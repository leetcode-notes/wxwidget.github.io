<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Yang Cheng]]></title>
  <link href="http://wxwidget.github.io/atom.xml" rel="self"/>
  <link href="http://wxwidget.github.io/"/>
  <updated>2014-08-18T20:20:07+08:00</updated>
  <id>http://wxwidget.github.io/</id>
  <author>
    <name><![CDATA[杨程]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[大规模分布式深度网络]]></title>
    <link href="http://wxwidget.github.io/blog/2014/08/17/large-scale-deep-network/"/>
    <updated>2014-08-17T17:12:00+08:00</updated>
    <id>http://wxwidget.github.io/blog/2014/08/17/large-scale-deep-network</id>
    <content type="html"><![CDATA[<h2 id="section">摘要</h2>

<p>最近关于无监督特征学习（unsupervised feature learning）和深度学习（deep learning）的工作表明，具有训练大型模型能力的系统能够显著地提升深度神经网络的训练效果。在这篇文章中，我们针对的问题是利用多达10^4数量的CPU来训练一个具有10^9数量的参数（parameter）的深度网络。为了达到训练的目的，我们开发了称为DistBelief的软件框架，其利用具有上千节点（译者注：为了一致性，译文中的节点均指机器，即计算节点；而神经网络中的节点，均称为单元）的计算集群来训练大型模型。</p>

<!--more-->

<p>在该框架中，实现了两个算法用于大规模分布训练：</p>

<ol>
  <li>Downpour（译者注：猜测这里的Downpour主要是指并行地参数更新，就像倾盆大雨中，雨点从多处同时落下一样）SGD（stochastic gradient descent），一个支持大量模型副本的异步随机梯度下降过程。</li>
  <li>Sandblaster（译者注：形容来自coordinator的命令像砂粒一样喷向集群其他节点），一个支持多种批量（batch）计算的分布优化方法，包含了L-BFGS的分布式实现，Downpour SGD和Sandblaster L-BFGS 都具有提升系统扩展能力和加速深度网络训练的能力。</li>
</ol>

<p>我们已经成功地利用DistBelief训练出一个比先前研究中提到的大30余倍的深度网络模型，并且获得了针对ImageNet（一个具有21K个分类和10M图像视觉识别任务）的最先进的训练效果。同时，我们还证明了，以上提及的技术能够显著地提升一个中等大小的，用作商用语音识别服务的深度网络的训练效果。尽管我们的这些技术主要用在大型神经网络的训练上，但是相关的算法同样适用于任何基于梯度的机器学习算法。</p>

<h3 id="section-1">1.介绍</h3>

<p>深度学习和无监督特征学习给许多实际应用带了新的巨大希望。它在包括语音识别[1, 2]、视觉物体识别[3, 4]和文本处理[5, 6]等不同领域上体现了最领先的性能优势和效果。
先前研究已经证明，通过增加样本数量和模型参数数量等不同手段，可以显著地提升分类算法的最终精确度[3, 4, 7]。该结论掀起了研究可扩展的深度学习训练和推断算法和提高其适用性等优化方法的热潮[7, 9]。近年来，在中等大小深度网络的训练上，一个重要的进步是因GPU的使用，使其变得更加的实用[1, 2, 3, 8]。但GPU众所周知的缺陷是，当其内存（通常小于6G）无法存放下模型时，训练的提升效果变得不再明显。这时，为了有效地使用GPU，研究者往往通过减少样本或变量规模的途径使得CPU和GPU之间的数据交换不在成为瓶颈。虽然数据或变量的减少对小规模问题（如针对于声学模型的语音识别）有效，但对具有大量样本和高维度变量的问题（如高分辨率图像）将失去效果。</p>

<p>在本文中，我们提出了一个替代的方法，使用大规模的计算集群来分布地对深度网络进行训练和推断。我们开发了一个既能提升节点内（通过多线程方式）又可提升节点间（通过消息传递）并行训练能力的软件框架，称为DistBelief。它管理了如并行计算、同步化和通信等底层的细节。除了支持模型并行，DistBelief同时还支持数据并行，通过单一模型的多个分布副本的方式来优化同一目标。在该框架中，我们设计并实现了两个用于大规模分布式训练的新方法：i)Downpuur SGD，一个利用自适应学习速率和支持大量模型副本的异步随机梯度下降过程；(ii)Sandblaster L-BFGS，L-BFGS过程的一个分布式实现，其利用了数据和模型的并行（原作者注：我们利用Sandblaster方法实现了L-BFGS，但是Sandblaster同样广泛适用于其他批量方法的优化）。两个方法相比较于常规的SGD或L-BFGS方法都获得了显著的速度提升。
关于大规模非凸方法优化，我们的实验呈现了一些出人意料的结果。首先，异步梯度下降，一个很少被用到非凸问题的方法，尤其是与Adagrad[10]自适应学习速率结合时，用以训练深度网络的效果很好。其次，当计算资源充足时，L-BFGS方法能够和许多SGD的变种方法相匹敌，甚至优于后者。
对于深度学习的特定应用，我们提出了两项发现：前面提及的分布式优化方法，不仅可以加速中等规模模型的训练，同时它也可以训练规模大于想象的模型。为了证明第一点，我们利用分布式集群来训练中等大小语音识别模型，获得了与GPU相同的分类精度，而耗时仅是后者的1/10。为了证明第二点，我们训练了一个具有1G数量参数的大型神经网络，并用训练结果把ImageNet（计算机视觉领域最大的数据库之一）判别分类结果提升到了最先进的水平。</p>

<h3 id="section-2">2.前期工作</h3>

<p>近年来，用于商业和学术的机器学习数据集呈空前增长的趋势。因此，一些研究者开始探索可扩展的机器学习算法来处理这些泛洪数据[11, 12, 13, 14, 15, 16, 17]。但大量的研究仍着眼于线性凸模型[11, 12, 17]。在凸模型中，分布式梯度计算自然是第一步，但是有时因为同步的问题会遭遇训练速度减慢。针对该问题，已经有一些有效果的工作，如异步随机梯度下降算法中的无锁参数更新（如Hogwild![19]）。不幸的是，将这些方法扩展到的非凸情况的研究，如处理训练深度网络中遇到的问题，还是一片未知的领域。特别地，在存在多个局部最小解的情况下，是否能够使用参数平均或者执行密集的异步参数更新方法，还是未知的问题。
在深度学习范畴中，大多数工作仍然集中在利用单节点训练较小规模模型（如Theano[20]）上。关于向上扩展深度学习的一些有意思的建议是，利用GPU来训练多个小型模型，然后将分别的预测结果取平均[21]，或者修改标准的深度网络使其能够从本质上并行化。而与这些前期工作不同，我们关注于扩展深度网络用于训练具有10^9参数数量的超大模型，同时避免给模型形式引入限制。在分布式扩展方面，模型的并行，其思想和[23]类似，是一个主要的组成部分，同时其也必须和巧妙的分布优化方法相结合以利用数据的并行性。
我们也考虑了用一些现有的大规模计算工具，如Mapreduce和GraphLab等来处理大规模深度学习。我们发现为数据并行处理而设计的Mapreduce，极其不适合深度网络训练中固有的迭代计算；而用于通用（通常是无结构的）图计算的GraphLab，同样没有利用深度网络中典型的分层图结构来提升计算效率。</p>

<h3 id="section-3">3.模型并行</h3>

<p>为了使超大规模深度网络的训练变得容易，我们开发了软件框架——DistBelief，用以支持神经网络的并行计算和分层图形模型。用户只需定义发生在每个单元上的计算过程以单元在向上传递和向下传递（原作者注：对于神经网络而言，“向上”和“向下”指的是“前馈”和“反向传播”，而对于隐式Markov模型，它们与“前向”和“后向”意思更相近）时需发送的消息。对于大型模型，用户可能会将模型加以划分（如图1所示），使得不同节点的计算任务被分配到了不同机器上。DistBelief自动地利用CPU资源将节点内计算并行化，同时它还管理了底层通信、同步化和在训练和推断时的机器间数据传输。
将深度网络分布到多个机器上所带来的性能提升主要取决于模型的连通结构和计算需求。具有大量参数或高计算需求的模型通过增加CPU和内存数量通常可以提升训练速度，直到增加到通信开销成为系统的瓶颈。我们已成功地在144个划分（机器）上运行DistBelief框架，且获得了显著的性能提升，同时在8或16个划分上运行的一个中等大小模型，也获得了很好的效果（请参考第5节中模型并行化基准测试中的实验结果）。显然地，局部连通的网络模型，因为需要更少的网络通信，所以比全连通网络模型更易于分布化。导致性能退化的一个主要原因是因不同机器上处理时间的不同，导致大量的机器在等待一个或单个节点完成本阶段任务（译者注：和MapReduce中Map阶段的长尾问题类似）。尽管如此，对于我们最大的模型来讲，我们仍可以高效地用总共有512核CPU 的32台机器（每台机器平均使用16核CPU的计算资源）来训练单个神经网络。当和下一节中讲到的利用模型多副本方法的分布式优化算法相结合时，将使得在多达10K的CPU数量上训练单个网络成为可能，从而进一步减少总的训练时间。</p>

<h3 id="section-4">4.分布式优化算法</h3>

<p>DistBelief框架中的并行计算方法使我们能够部署和运行比前期工作中提到的大得多的神经网络模型。但是为了在合理时间内训练如此规模的模型，这就要求我们不仅需实现单个DistBelief实例内的并行，而且需要将训练任务分发到多个DistBelief实例。在本节中，我们将具体阐述这第二级的并行，即采用多个DistBelief模型的实例（或副本），同时来达到一个优化目标。</p>

<p><img src="http://wxwidget.github.io/images/large_scale.png" alt="算法示意图" /></p>

<ul>
  <li>左：Downpour SGD，模型的副本采用异步方式从参数服务器（Parameter Server）中获取参数w和上传<script type="math/tex">\Delta w</script>到参数服务器。</li>
  <li>右：Sandblaster L-BFGS：单个协调器（Coordinator）实例发送简短消息（message）到模型副本和参数服务器以协调批量优化过程。</li>
</ul>

<p>下面我们来对这两个分布优化方法做比较：Downpour SGD是在线方法，而L-BFGS是批量方法。两方法中模型副本都利用了中心分割化服务器组的概念来共享参数，也都利用了每个模型副本中DistBelief的并行性。但更重要的是，对不同副本的处理时间的不同，甚至整个模型副本的失效、移除和重启等情况都在两方法的考虑范围之内。</p>

<h4 id="downpour-sgd">4.1 Downpour SGD</h4>

<p>随机梯度下降（SGD）方法，应该是最常用的训练深度神经网络的优化方法[26, 27, 3]。但不幸的是，传统SGD方法本质上的顺序性，使得在大型数据集下变得不再适用，因为这种完全串行方式所需要的机器间数据移动是非常耗时的。</p>

<p>为了将SGD应用到大数据集上，我们提出了Downpour SGD，一个使用单个DistBelief模型的多个分布副本的异步随机梯度下降变种。它的基本方法如下：将训练集划分若干子集，并对每个子集运行一个单独的模型副本。模型副本之间的通信均通过中心参数服务器组，该参数服务器组维护了模型参数的当前状态，并分割到多台机器上（例如，如果我们参数服务器组有10个节点，那么每个节点将负责存储和更新模型参数的1/10，如图1所示）。该方法在两个方面体现异步性：</p>

<ol>
  <li>模型副本之间运行独立</li>
  <li>参数服务器组各节点之间同样是独立的。</li>
</ol>

<p>考虑Downpour SGD的一个最简单的实现，在处理每个mini-batch（译者注：小型批量）之前，模型副本都会向参数服务器请求最新的模型参数。因为DistBelief框架也是分布在多台机器上，所以其框架的每个节点只需和参数服务器组中包含和该节点有关的模型参数的那部分节点进行通信。在DistBelief副本获得更新后的模型参数后，运行一次mini-batch样本来计算参数的梯度，并推送到参数服务器，以用于更新当前的模型参数值</p>

<p>可以通过设定每<script type="math/tex">n_{fetch}</script> 次mini-batch操作向参数服务器获取一次更新后的参数和每<script type="math/tex">n_{push}</script>次mini-batch操作推送一次梯度更新到参数服务器（这里<script type="math/tex">n_{fetch}</script>不一定和<script type="math/tex">n_{push}</script>相等）。事实上，获取参数，推送梯度和处理训练样本三种操作，可以以三个采用弱同步的线程实现（参见附录中的伪代码）。为了简单起见，同时也是为了和传统SGD方法相比较，在下面的实验中，我们设定: <script type="math/tex">n_{fetch}=n_{push}=1</script></p>

<p>在处理机器失效方面，Downpour SGD比标准（同步）SGD要鲁棒。对于同步SGD来讲，如果一台机器失效，整个训练过程将会延时；但是对于异步SGD来讲，如果某个模型副本的一台机器失效，其他模型副本仍然继续处理样本并更新参数服务器中的模型参数。另一方面，Downpour SGD带来的多种异步处理形式给优化过程带来了进一步的随机性。这里面最显而易见的是，模型实例最可能是使用一个稍微过时的参数来计算梯度，因为这时其他的副本可能已经更新了参数服务器上的参数。但是，除此之外还有其他随机的来源：因为参数服务器组的每台机器是行为独立的，所以无法保证在给定时间点上，每个节点的参数被更新的次数相同，或者以同样的顺序被更新。更进一步的，因为模型副本使用不同的线程来获取参数和推送梯度值，故在同一时间戳上，单个副本内的参数将有额外的稍微不一致的现象。尽管对于非凸问题的这些操作的安全性缺乏理论基础，但是在实践中，我们发现放松一致性要求的做法是相当有效的。</p>

<p>我们发现，另外一项能极大提高Downpour SGD鲁棒性的技术是使用Adagrad[10]自适应学习速率方法。与使用固定的值作为学习速率的方式不同，Adagrad的每个参数使用单独的自适应学习速率。假设是<script type="math/tex">$\eta_{i,k}</script>第i个参数在第k次迭代时的学习速率,<script type="math/tex">\Delta g_{i,k}</script>是其梯度值，那么：</p>

<script type="math/tex; mode=display">
\eta_{i,k} = \frac{\gamma}{\sqrt{\sum_{j=1}^{k} g_{i,j}}}
</script>

<p>可以看出，因为学习速率的计算仅与参数历史梯度值的平方和有关，所以Adagrad易于在每个参数服务器节点上单独实现。所有学习速率共享的缩放常量因子γ，通常大于（可能有一个数量级）不使用Adagrad情况下，采用固定学习速率的最优值。Adagrad的使用能够增加并发训练的模型副本数量，同时，采用“热启动”（即在启动其他副本之前，用单个模型来训练参数）的模型训练方法，几乎消除了在Downpour SGD中可能会出现的稳定性问题.</p>

<p><img src="http://wxwidget.github.io/images/downpour.jpeg" alt="算法1" /></p>

<h4 id="sandblaster-l-bfgs">4.2 Sandblaster L-BFGS</h4>

<p>已经证实批量处方法在小型深度网络的训练上效果很好[7]。为了将这些方法运用到大型模型和大型数据集上，我们引入了Sandblaster批量优化框架，同时讨论了L-BFGS在该框架的一个实现。
Sandblaster的主要思路是将参数的存储和操作分布化，算法（如L-BFGS）的核心位于协调器（coordinator）中。该协调器并不直接获取模型参数，相反地，它发出一系列命令（如内积，向量缩放，系数相关加法，乘法）到参数服务器节点，并且这些命令能在节点范围内执行。一些额外的信息，如L-BFGS的历史数据缓存，同样保存在计算出它的参数服务器节点上。这使得运行大型模型（10亿级参数）成为现实，而且不会因传输参数和梯度过度集中在一个节点上而导致性能下降。
在典型的L-BFGS的并行实现中，数据被分布到许多机器上，每个机器负责对样本数据的一个特定的子集计算梯度，而后梯度值被传输回中心服务器（或者通过树形结构来聚合[16]）。因为许多方法都需要等待最慢的机器处理完毕，所以它并不能很好地扩展到大型共享集群中。为了解决该（扩展性）问题，我们采用了如下的负载均衡的方案：协调器分配给这N个模型副本一小部分的任务量，并且该计算任务远小于总批量，每当副本完成计算处于闲置状态时，立即给其分配新的计算任务，如此下去。为了在整个批量计算的最后阶段进一步优化慢速副本的任务处理，协调器调度最快结束的副本同时计算未完成的任务，从最先结束的副本处取得计算结果。该方案和MapReduce中的“备份任务”的使用相类似[24]。数据预取方式和通过将顺序数据传输到同一生产者以提高数据亲和性的方法一道，使得数据的获取不再是问题。和Downpour SGD中和参数服务器之间的高频率，高吞吐参数同步方式相反，Sandblaster中的计算者仅仅需在每次批处理的开始阶段获取参数，并且只需在极少的结束部分（用以免遭备份失效和重启）处需要传输梯度到参数服务器。</p>

<p><img src="http://wxwidget.github.io/images/sandblaster.jpeg" alt="算法2" /></p>

<h4 id="section-5">5.实验</h4>

<h4 id="section-6">6.结论</h4>
<p>在这篇文章中，我们介绍了DistBelief，一个深度网络的分布并行训练的框架，并在该框架中发现了一些有效的分布优化策略。我们提出了Downpour SGD，一个高度异步的SGD变种算法，用以训练非凸的深度学习模型，其结果出乎意料的好。Sandblaster L-BFGS， L-BFGS的分布式实现，其与SGD相比具有竞争力。同时，对网络带宽的高效利用，使得其能够扩展到更大数量的并发线程来训练同一模型。这就是说，当具有2000数量CPU或更少时，Downpour SGD和Adagrad自适应学习速率方法的结合是最有效的方法。
Adagrad方法本身不是为异步SGD的使用而设计的，并且该方法最典型的应用也不是在非凸问题上。但是，在高度非线性的深度网络中，两者的结合的效果却如此的好。我们推测，在面对剧烈的异步更新时，Adagrad自动地对不稳定参数起到了稳定的效果，并且很自然地根据不同的深度网络层数的变化来调整学习速率。
实验结果表明，即使在中等规模的模型训练上，使用我们的大规模（分布式）方法，集群方法也比GPU要快，并且没有GPU对模型规模的限制。为了证明其训练更大模型的能力，我们通过训练一个超过10^9数量参数的模型，在ImageNet物体识别上获得了比先前最优的更好的精度水平。</p>

<h4 id="references">References</h4>

<ol>
  <li>
    <p>G.  Dahl, D.  Yu, L.  Deng, and A.  Acero.  Context-dependent pre-trained deep neural networks for large vocabulary speech recognition.  IEEE Transactions on Audio, Speech, and Language Processing, 2012. </p>
  </li>
  <li>
    <p>G.  Hinton, L.  Deng, D.  Yu, G.  Dahl, A.  Mohamed, N.  Jaitly, A.  Senior, V.  Vanhoucke, P.  Nguyen, T.  Sainath, and B.  Kingsbury.  Deep neural networks for acoustic modeling in speech recognition.  IEEE Signal Processing Magazine, 2012. </p>
  </li>
  <li>
    <p>D.  C.  Ciresan, U.  Meier, L.  M.  Gambardella, and J.  Schmidhuber.  Deep big simple neural nets excel on handwritten digit recognition.  CoRR, 2010. </p>
  </li>
  <li>
    <p>A.  Coates, H.  Lee, and A.  Y.  Ng.  An analysis of single-layer networks in unsupervised feature learning.  In AISTATS 14, 2011. </p>
  </li>
  <li>
    <p>Y.  Bengio, R.  Ducharme, P.  Vincent, and C.  Jauvin.  A neural probabilistic language model.  Journal of Machine Learning Research, 3:1137–1155, 2003. </p>
  </li>
  <li>
    <p>R.  Collobert and J.  Weston.  A unified architecture for natural language processing: Deep neural networks with multitask learning.  In ICML, 2008. </p>
  </li>
  <li>
    <p>Q. V.  Le, J.  Ngiam, A.  Coates, A.  Lahiri, B.  Prochnow, and A. Y.  Ng.  On optimization methods for deep learning.  In ICML, 2011. </p>
  </li>
  <li>
    <p>R.  Raina, A.  Madhavan, and A.  Y.  Ng.  Large-scale deep unsupervised learning using graphics processors.  In ICML, 2009. </p>
  </li>
  <li>
    <p>J.  Martens.  Deep learning via hessian-free optimization.  In ICML, 2010. </p>
  </li>
  <li>
    <p>J.  C.  Duchi, E.  Hazan, and Y.  Singer.  Adaptive subgradient methods for online learning and stochastic optimization.  Journal of Machine Learning Research, 12:2121–2159, 2011. </p>
  </li>
  <li>
    <p>Q.  Shi, J.  Petterson, G.  Dror, J.  Langford, A.  Smola, A.  Strehl, and V.  Vishwanathan.  Hash kernels.  In AISTATS, 2009. </p>
  </li>
  <li>
    <p>J.  Langford, A.  Smola, and M.  Zinkevich.  Slow learners are fast.  In NIPS, 2009. </p>
  </li>
  <li>
    <p>G.  Mann, R.  McDonald, M.  Mohri, N.  Silberman, and D.  Walker.  Efficient large-scale distributed training of conditional maximum entropy models.  In NIPS, 2009. </p>
  </li>
  <li>
    <p>R.  McDonald, K.  Hall, and G.  Mann.  Distributed training strategies for the structured perceptron.  In NAACL, 2010. </p>
  </li>
  <li>
    <p>M.  Zinkevich, M.  Weimer, A.  Smola, and L.  Li.  Parallelized stochastic gradient descent.  In NIPS, 2010. </p>
  </li>
  <li>
    <p>A.  Agarwal, O.  Chapelle, M.  Dudik, and J.  Langford.  A reliable effective terascale linear learning system.  In AISTATS, 2011. </p>
  </li>
  <li>
    <p>A.  Agarwal and J.  Duchi.  Distributed delayed stochastic optimization.  In NIPS, 2011. </p>
  </li>
  <li>
    <p>C.  H.  Teo, Q.  V.  Le, A.  J.  Smola, and S.  V.  N.  Vishwanathan.  A scalable modular convex solver for regularized risk minimization.  In KDD, 2007. </p>
  </li>
  <li>
    <p>F.  Niu, B.  Retcht, C.  Re, and S.  J.  Wright.  Hogwild! A lock-free approach to parallelizing stochastic gradient descent.  In NIPS, 2011. </p>
  </li>
  <li>
    <p>J.  Bergstra, O.  Breuleux, F.  Bastien, P.  Lamblin, R.  Pascanu, G.  Desjardins, J.  Turian, D.  Warde-Farley, and Y.  Bengio.  Theano: a CPU and GPU math expression compiler.  In SciPy, 2010. </p>
  </li>
  <li>
    <p>D.  Ciresan, U.  Meier, and J.  Schmidhuber.  Multi-column deep neural networks for image classification.  Technical report, IDSIA, 2012. </p>
  </li>
  <li>
    <p>L.  Deng, D.  Yu, and J.  Platt.  Scalable stacking and learning for building deep architectures.  In ICASSP, 2012. </p>
  </li>
  <li>
    <p>A.  Krizhevsky.  Learning multiple layers of features from tiny images.  Technical report, U.  Toronto, 2009. </p>
  </li>
  <li>
    <p>J.  Dean and S.  Ghemawat.  Map-Reduce: simplified data processing on large clusters.  CACM, 2008. </p>
  </li>
  <li>
    <p>Y.  Low, J.  Gonzalez, A.  Kyrola, D.  Bickson, C.  Guestrin, and J.  Hellerstein.  Distributed GraphLab: A framework for machine learning in the cloud.  In VLDB, 2012. </p>
  </li>
  <li>
    <p>L.  Bottou.  Stochastic gradient learning in neural networks.  In Proceedings of Neuro-Nˆımes 91, 1991. </p>
  </li>
  <li>
    <p>Y.  LeCun, L.  Bottou, G.  Orr, and K.  Muller.  Efficient backprop.  In Neural Networks: Tricks of the trade.  Springer, 1998. </p>
  </li>
  <li>
    <p>V.  Vanhoucke, A.  Senior, and M.  Z.  Mao.  Improving the speed of neural networks on cpus.  In Deep Learning and Unsupervised Feature Learning Workshop, NIPS 2011, 2011. </p>
  </li>
  <li>
    <p>J.  Deng, W.  Dong, R.  Socher, L. -J.  Li, K.  Li, and L.  Fei-Fei.  ImageNet: A Large-Scale Hierarchical</p>
  </li>
</ol>

<p>Image Database.  In CVPR, 2009. 
30.  Q. V.  Le, M. A.  Ranzato, R.  Monga, M.  Devin, K.  Chen, G. S.  Corrado, J.  Dean, and A. Y.  Ng.  Building high-level features using large scale unsupervised learning.  In ICML, 2012. </p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[流量分配和全局优化问题]]></title>
    <link href="http://wxwidget.github.io/blog/2014/07/27/product-schedule-problem/"/>
    <updated>2014-07-27T12:18:00+08:00</updated>
    <id>http://wxwidget.github.io/blog/2014/07/27/product-schedule-problem</id>
    <content type="html"><![CDATA[<h2 id="section">问题定义</h2>

<p>流量的全局优化是指同整体的角度看，通过控制流量在商品，类目，品牌，店铺的分配，提升用户的UV价值的方法。算法的链接的是用户的需求，和商家的供给，
通过分流，定价等方式调节市场。在大规模的促销活动中，常常会看到供给和需求的极度不平衡，以加入购物车的量和库存比值为例, 大量的商品无人问津，少量的
商品供不应求。借助广告中最优匹配算法工具，优化双11的流量调配机制。</p>

<p>假设提供有m件商品,n位用户，以下信息是已知的</p>

<ul>
  <li>$f_i$, 商品i的库存量</li>
  <li>$v_i$, 用户i期望到达次数</li>
</ul>

<p>同时我们通过预测方法，可以知道</p>

<ul>
  <li>$p_{ij}$用户i，对商品j可能的购买概率</li>
</ul>

<!-- more -->

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[机器学习的通用指南: 优化理论]]></title>
    <link href="http://wxwidget.github.io/blog/2014/05/26/numeric-optimization/"/>
    <updated>2014-05-26T11:18:00+08:00</updated>
    <id>http://wxwidget.github.io/blog/2014/05/26/numeric-optimization</id>
    <content type="html"><![CDATA[<p>通常我们会把机器学习过程分成两个阶段，建模阶段和求解阶段。在大数据的推动下，求解的问题慢慢大于建模的问题。比如，业界一般采用逻辑回归做CTR预估或者其他的预测模型，但是在数据规模非常大的条件下，如何在分布式的环境下，更快更准的求解模型就变得非常重要。精确的解析求解场景是非常少的，人们更多的去研究模型的数值求解过程，比如梯度下降法；近似求解，比如：蒙特卡洛法。这里我只想讨论下梯度下降法，该方法是一种非常神奇的通用的数学最优化方法。</p>

<p>下面会分几个阶段去讲梯度法的基本原理，本文更多的是偏理解。</p>

<ol>
  <li>梯度下降法</li>
  <li>牛顿法</li>
  <li>拟牛顿法</li>
  <li>共轭梯度法</li>
</ol>

<!-- more -->

<h2 id="section">符号说明</h2>

<ul>
  <li>$x$表示自变量</li>
  <li>$y$表示因变量，是自变量的函数$y(x)$</li>
  <li>$\nabla$ 梯度算子</li>
  <li>$\eta$ 学习率，大于0的数</li>
  <li>g 或者$\nabla f$ 一阶梯度，</li>
  <li>H 或者$\nabla^2 f$ 二阶梯度</li>
</ul>

<h2 id="section-1">梯度法</h2>

<p>简单的无约束的优化问题是，找到使得f(x)取最小值时的x。迭代法的基本思路是找到一种迭代的方法, x变化导致y下降,用数学的方法表示就是。</p>

<script type="math/tex; mode=display">
x_{k+1} = x_k + p = x_k + \eta d
</script>

<p>其中p表示x的增加的部分，分解成大小$\eta$，和方向$d$</p>

<p>我们先得知道函数的近似公式：</p>

<div class="definition">
    一阶泰勒展开公式: 
    $$f(x_k+p) = f(x_k)+ \nabla f(x_k) p + O(p^2)$$
    去掉无穷小部分:
    $$f(x+p) = f(x)+ g^Tp  $$
</div>

<p>从一阶的泰勒展开公式我们可以知道要想使得更新后的函数$f(x+p) \leq f(x)$，必须使得 $g^T*p \leq 0$，我们又知道g和d都是向量,
他们的向量表示法：</p>

<script type="math/tex; mode=display">
    g^Tp = |g|*|p|*cos \theta
</script>

<p>只要保证$theta$小于0，就可以保证 $g^Tp$小于0。使得$p = -\eta g$， 这就是传说中的最速梯度法了.</p>

<div class="definition">
    梯度下降法: 
    $$p = -\eta * g,  满足 \eta \gt 0 $$
    那么x写成迭代形式是
    $$
    x_{k+1} = x_k - \eta * g
    $$
</div>

<p>通过梯度下降法，我们知道，我们确实有一种方法，能找到x的一种迭代方式，使得函数y不增加。$x_{k+1} = x_k + \eta *g $中我们只解决了方向的问题，
还有一个学习率的问题没有解决。就是我们如何确定 $\eta$，有一种非常简单的方法是预设$\eta$为一个固定的值比如0.1；或者
$\eta$是在一个区间了下降，比如从0.5下降到0.001；或者不同的x的分量有不同的学习率，等等。这些方法通常表现都不错</p>

<h2 id="section-2">牛顿法</h2>

<p>为了得到更快的收敛速度，挑选合适的学习速率也是一件比较困难的事情。回到泰勒展开公式，我们知道还有一个更加精确的二阶泰勒展开公式</p>

<div class="definition">
    二阶泰勒展开公式: 
    $$f(x_k+p) = f(x_k)+ \nabla f(x_k) p + \frac{1}{2} p^T \nabla ^2 f(x_k) p $$
    知道 $p = x - x_k$得到:
    $$f(x) = f(x_k)+ \nabla f(x_k) (x-x_k) + \frac{1}{2} (x-x_k)^T \nabla ^2 f(x_k) (x-x_k) $$
</div>

<p>我们知道函数极值的条件是倒数为0,所以</p>

<script type="math/tex; mode=display"> \frac{\partial f}{\partial x} = 0 </script>

<p>求解得到</p>

<script type="math/tex; mode=display"> x = {x_k} - \frac{\nabla f({x_k})}{\nabla ^2 f({x_k})} = {x_k} - {H^{ - 1}}g</script>

<p>当然算法工程通常不会直接求H的逆，而是通过 $Hp ＝ －g$去计算p</p>

<p>牛顿法的好处是对强二次型的函数效果收敛速度非常快，但是对非二次型的函数很有可能导致迭代过程中函数上升。</p>

<h2 id="line-search">line search</h2>

<p>为了避免此类问题，出现了line search方法：</p>

<script type="math/tex; mode=display">
 \eta_k = argmin \ f(x_k + \eta_k p_k) 
  \\
  x_{k+1}=x_k-\eta_k g_k
</script>

<p>我们知道要想使得函数f最小，满足
$$
\frac{\partial f(x_{k+1})} {\partial \eta}=0
$$</p>

<p>更加函数的求导数法则</p>

<script type="math/tex; mode=display">
\frac{\partial f(x_{k+1})} {\partial \eta} = 
\frac{\partial f(x_{k+1})}{\partial x_{k+1}} \times \frac{\partial x_{k+1}}{\partial \eta_k} = g_{k+1} g_{k} = 0
</script>

<p>即为了满足line search的条件，需要将下一次的迭代方向和本次的迭代方向垂直。这就是衍生出共轭梯度法了。</p>

<p>当然，<a href="http://en.wikipedia.org/wiki/Line_search">line search</a>其实有很多其他的启发式方法，比如最直观<a href="http://en.wikipedia.org/wiki/Backtracking_line_search">backtracing法</a></p>

<h2 id="section-3">拟牛顿法</h2>

<p>我们再回到牛顿法的Hession矩阵H和$H^{-1}$上，我们知道每一步如果都求解H或者$H^{-1}$是非常耗费时间的，拟牛顿法的思路是，通过近似的方法加迭代的思路求H。回到二阶的泰勒公式：</p>

<script type="math/tex; mode=display">f(x) = f(x_k)+ \nabla f(x_k) (x-x_k) + \frac{1}{2} (x-x_k)^T \nabla ^2 f(x_k)</script>

<p>对f(x)求导数：</p>

<script type="math/tex; mode=display">
 g(x) = g(x_k) + H_k(x-x_k)
 </script>

<p>另x为$x_{x+1}$,</p>

<script type="math/tex; mode=display">
 g(x_{k+1}) - g(x_k) = H_k(x_{k+1}-x_k)
 </script>

<p>再另<script type="math/tex">y_k=g(x_{k+1})-g(x_k), s_k=x_{k+1}-x_k</script>,可以简写为：</p>

<p>$$
 y_k = H_k s_k
 $$
 $$
 s_k = H^{-1}_k y_k
 $$</p>

<p>这就是拟牛顿法的条件公式。</p>

<h3 id="dfp">DFP算法</h3>

<p>DFP是3个人名称的首字母，想看八卦可以参考<a href="http://en.wikipedia.org/wiki/Davidon%E2%80%93Fletcher%E2%80%93Powell_formula">DFP</a>,DFP的思想很直接，我们不是要求逆矩阵$H^{-1}$吗？是不是可以找到一直简单的迭代方式，比如：
$$
	H^{-1}_{k+1} = H^{-1}_k + \delta H^{-1}
$$</p>

<p>我们要求H是正定矩阵（原因以后解释），那么就假设一种简单的形式
$$
\delta H^{-1} = \alpha * w w^T + \beta * u u^T
$$</p>

<p>ok，到目前我们带入到拟牛顿条件公式  <script type="math/tex"> s_k = H^{-1}_k y_k </script>，</p>

<script type="math/tex; mode=display">
( H^{-1}_k  + \alpha * w w^T + \beta * u u^T) \times y_k = s_k
</script>

<p>注意到w，u和y都是向量，那么$w^Ty$,$u^Ty$都是表量。
$$
H^{-1}_k y_k + \alpha * w w^T y_k + \beta * u u^T y_k = s_k
$$</p>

<script type="math/tex; mode=display">
(\alpha w^T y_k) * w + (\beta  u^T y_k) u = s_k － H^{-1}_k y_k  
</script>

<p>天啦，这个方程如何求解呢？但是，我们只需要找到一组可行的解就ok了，好吧，那么我们就另：</p>

<p>$$
\alpha w^T y_k = 1, =&gt; \alpha = \frac{1} {w^T y_k}
$$
$$
\beta  u^T y_k = -1, =&gt; \beta = \frac{1} {u^T y_k}
$$</p>

<p>那么
$$
w - u = s_k － H^{-1}_k y_k<br />
$$</p>

<p>呵呵，还是不能解，能在简单点吗？行！
$$
w = s_k
u = H^{-1}_k y_k<br />
$$</p>

<p>就这样我们得到:</p>

<script type="math/tex; mode=display">
\alpha = \frac{1} {s_k^T y_k}
</script>

<script type="math/tex; mode=display">
\beta = \frac{1} {H^{-T}_k y_k}
</script>

<script type="math/tex; mode=display">
H^{-1}_{k+1} = \alpha s_k s_k^T + \beta H^{-1}_k y_k y_k^T H^{-T}_k
</script>

<p>到这里DFP我们就完成了$H^{-1}$的迭代求解过程。</p>

<h3 id="bfgs">BFGS</h3>

<p>BFGS和DFP非常的类似，但是他利用拟牛顿条件公式，H（注意不是$H^{-1}$）做近似，然后在通过Sherman Morrison公式计算$H^{-1}$。是目前表现最好的拟牛顿算法。</p>

<p>和DFP一样，我么只需要兑换s和y的位置就可以得到H的近似公式，然后在计算$H^{-1}$,这里我就不详细讨论了，直接拿结果吧
$$
H_{k+1} = \frac{y_k y_k^T} {y_k^T y_k} + \frac{ H_k s_k s_k^T H^T_k } {H^T_k s_k}
$$</p>

<div class="definition">
BFGS Hession矩阵迭代方程：
$$
H^{-1}_{k+1} = (I - \frac{s_k y^T_k} {y^T_k s_k})H^{-1}_k(I-\frac{y_k s^T_k} {y^T_k s_k}) + \frac{s_k s^T_k} {y^T_k s_k}
$$
</div>
<p>更多见<a href="http://en.wikipedia.org/wiki/Quasi-Newton_method">wiki</a></p>

<h3 id="lbfgs">LBFGS算法</h3>

<p>BFGS算法需要记录H，当问题的维度比较高的时候，说需要的存储空间是非常大的。LBFGS又成为Limited－Memory BFGS算法，它对内存进行了优化。</p>

<p>我们从BFGS的公式知道 <script type="math/tex">H^{-1}_{k+1}</script>总是从(s<em>0,y</em>0),(s<em>1,y</em>1),…,(s_k,y_k)计算得到，因此我们完全不必要存储 $O(n^2)$内存，二存储 $O(k n)$ 具体的算法因为不设计到原理性的算法问题，这里就不讨论，如果想了解，可以参考<a href="http://en.wikipedia.org/wiki/Limited-memory_BFGS">LBFGS</a></p>

<p>主要我们并不是要求出$H^{-1}$,而是 $H^{-1}g_k$</p>

<p>当然LBFGS有很多变种，其中比较重要的是：</p>

<ul>
  <li>LBFGS-B：带条件约束的LBFGS</li>
  <li>OWL-QN： LBFGS with L1</li>
  <li>O-LBFGS： online learning版本</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[painless-conjugate-gradient]]></title>
    <link href="http://wxwidget.github.io/blog/2014/05/23/painless-conjugate-gradient/"/>
    <updated>2014-05-23T12:55:00+08:00</updated>
    <id>http://wxwidget.github.io/blog/2014/05/23/painless-conjugate-gradient</id>
    <content type="html"><![CDATA[<ul>
  <li><a href="http://www.csie.ntu.edu.tw/~cjlin/papers/logistic.pdf">liblinear实现</a></li>
  <li><a href="http://www.cs.cmu.edu/~quake-papers/painless-conjugate-gradient.pdf">简易教程</a></li>
  <li><a href="http://research.microsoft.com/en-us/um/people/minka/papers/logreg/minka-logreg.pdf">logistic regression对比</a></li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[large-scale-machine-learning]]></title>
    <link href="http://wxwidget.github.io/blog/2014/05/12/large-scale-machine-learning/"/>
    <updated>2014-05-12T12:49:00+08:00</updated>
    <id>http://wxwidget.github.io/blog/2014/05/12/large-scale-machine-learning</id>
    <content type="html"><![CDATA[<p><a href="http://www.cse.ust.hk/~kxmo/LargeML.html">link</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[em-algorithm]]></title>
    <link href="http://wxwidget.github.io/blog/2014/05/09/em-algorithm/"/>
    <updated>2014-05-09T10:15:00+08:00</updated>
    <id>http://wxwidget.github.io/blog/2014/05/09/em-algorithm</id>
    <content type="html"><![CDATA[<h2 id="links">links</h2>
<p>-<a href="http://blog.tomtung.com/2011/10/em-algorithm/">写的不错</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[expect_propagation]]></title>
    <link href="http://wxwidget.github.io/blog/2014/02/06/expect-propagation/"/>
    <updated>2014-02-06T16:44:00+08:00</updated>
    <id>http://wxwidget.github.io/blog/2014/02/06/expect-propagation</id>
    <content type="html"><![CDATA[<h2 id="link">link</h2>
<ul>
  <li><a href="http://dongguo.me/blog/2014/01/01/expectation-propagation/">hulu</a></li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[sparsity_and_regularization]]></title>
    <link href="http://wxwidget.github.io/blog/2014/02/06/sparsity-and-regularization/"/>
    <updated>2014-02-06T16:36:00+08:00</updated>
    <id>http://wxwidget.github.io/blog/2014/02/06/sparsity-and-regularization</id>
    <content type="html"><![CDATA[<h2 id="links">links</h2>
<p>-<a href="http://freemind.pluskid.org/machine-learning/sparsity-and-some-basics-of-l1-regularization">证明</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[在线学习]]></title>
    <link href="http://wxwidget.github.io/blog/2014/01/24/online-learning-survey/"/>
    <updated>2014-01-24T11:53:00+08:00</updated>
    <id>http://wxwidget.github.io/blog/2014/01/24/online-learning-survey</id>
    <content type="html"><![CDATA[<h2 id="section">故事</h2>

<p>在现实的世界里，故事是另外一个版本：在网络的一头住着一挨踢男，另一头住着一小编。每天小编写一封垃圾邮件给挨踢男。苦命的挨踢男日日分析邮件设计过滤器来过滤小编的垃圾邮件。但聪明的小编如果一发现邮件没有成功的被寄送，那么就会在下一封里加上更多的甜言蜜语来忽悠挨踢男。较量一直进行下去，挨踢男是否能摆脱小编的骚扰呢？</p>

<p>以上故事都属于博弈论里的重复游戏（repeated game），它是对在线学习（online learning）最贴切的刻画：数据不断前来，我们需根据当前所能得到的来调整自己的最优策略。</p>

<p>熟悉机器学习的可能注意到了在线学习与离线学习的区别。前者认为数据的分布是可以任意的，甚至是为了破坏我们的策略而精心设计的，而后者则通常假定数据是服从独立同分布。这两种不同的假设带来不一样的设计理念和理论。</p>

<!--more-->

<p>统计学习考虑算法所求得到的模型与真实模型的差距。数据由真实模型产生，如果能有无限数据、并在包含有真实模型的空间里求解，也许我们能算出真是模型。但实际上我们只有有限的有噪音的数据，这又限制我们只能使用相对简单的模型。所以，理想的算法是能够用不多的数据来得到一个不错的模型。</p>

<p>在线学习的一个主要限制是当前只能看到当前的和过去的数据，未来是未知，有可能完全颠覆现在的认知。因此，对在线学习而言，它追求的是知道所有数据时所能设计的最优策略。同这个最优策略的差异称之为后悔（regret）：后悔没能一开始就选定最优策略。我们的希望是，时间一久，数据一多，这个差异就会变得很小。因为不对数据做任何假设，最优策略是否完美我们不关心（例如回答正确所有问题）。我们追求的是，没有后悔（no-regret）。</p>

<p>如果与统计学习一样对数据做独立同分布假设，那么在线学习里的最优策略就是在得知所有数据的离线学习所能得到最优解。因此在线学习可以看成是一种优化方法：随着对数据的不断访问来逐步逼近这个最优解。</p>

<p>很早以前优化界都在追求收敛很快的优化算法，例如牛顿迭代法。而最近一些年，learning的人发现，这类算法虽然迭代几下就能迭出一个精度很高的解，但每一步都很贵，而且数据一大根本迭不动。而向来被优化界抛弃的在线学习、随机优化算法（例如stochastic gradient descent），虽然收敛不快，不过迭代代价很低，更考虑到learning算法的解的精度要求不高，所以在实际应用中这些方法通常比传统的优化算法快很多，而且可以处理非常大的数据。</p>

<p>当然，相对于老地主online learning，stochastic绝对是新贵。我会接下来谈这类算法，以及他们动辄数页的convergence rate的证明</p>

<p>下面是有公式的正文。</p>

<h2 id="section-1">准确定义</h2>

<p>我们把学生定义为Learning，老师定义为Environment。Online Learning的过程就是，learner不停的回答Environment提出的问题。
在$t$时刻，learner接收到一个领域问题$x_t$，learner提供一个答案$h_t$，同时environment会给出正确答案 $y_t$。
此时，learner就会有一个惩罚(loss) $l(h_t,y_t)$。当learner经过有无数这样的训练后，learner会学习到领域知识。
过程如下：</p>

<ol>
  <li>enviroment提出问题$x_t$ </li>
  <li>learner从策略集合$\mathcal{H}$中选着一个策略$h_t$,做出判断$h_t(x)$</li>
  <li>learner根据$loss(h_t(x),y_t)$学习</li>
  <li>repeat 1 如果有更多的问题</li>
</ol>

<p>那么如何衡量一个learner过程的好坏呢？这就引入了后悔值的概念：</p>

<script type="math/tex; mode=display">
\displaystyle R(T)=\sum_{t=1}^T\ell_t(h_t)-\min_{h\in\mathcal{H}}\sum_{t=1}^T\ell_t(h).
</script>

<p>h为最优策略</p>

<p>learner的目标就是每次挑不错的<script type="math/tex">h_t</script>来使得<script type="math/tex">R(T)</script>最小。<script type="math/tex">R(T)</script>是可以小于0的。毕竟最优策略是要固定h，而如果我们每次都能选择很好的<script type="math/tex">h_t</script>来适应问题<script type="math/tex">(x_t,y_t)</script>，可能总损失会更小。但这非常难。因为我们是要定好策略<script type="math/tex">h_t</script>，才能知道正确答案<script type="math/tex">y_t</script>。如果这个问题和以前的很不一样，答案也匪夷所思，那么猜对它而且一直都猜对的概率很小。而对于最优策略来说，它能事先知道所有问题和答案，所以它选择的最优策略的总损失较小的可能性更大。所以，我们一般只是关心平均$regretR(T)/T$是不是随着T变大而变小。</p>

<div class="mark">
    mark:1
</div>

<div class="definition">
    我们称一个online算法是不是no-regret，或者说online learnable的，意味着:
    $$\displaystyle \lim_{T\rightarrow\infty}\frac{R(T)}{T}\rightarrow 0.$$
</div>

<h2 id="section-2">算法</h2>
<p>摘录自libol</p>

<p><img src="http://wxwidget.github.io/images/online_learning_alg.png" alt="online_learner" /></p>

<h3 id="plaperceptron-learning-algorithm">感知学习算法PLA(Perceptron Learning Algorithm)</h3>

<p><a href="https://class.coursera.org/ntumlone-001/lecture">PLA</a>，可以简单理解成“知错就改”算法。当遇到一个错误的时候，
就修正算法。
当然PLA有很多限定条件:
假设机器要回答的问题是yes/no，目标<script type="math/tex">y \in \{-1,+1\}</script>,策略<script type="math/tex">h_t</script>是线性模型：<script type="math/tex">h_t=w_t^tx</script>。</p>

<p>PLA算法以如下两步不断循环：</p>

<ol>
  <li>
    <p>find a <strong>misstake</strong> of <script type="math/tex">w_t</script> call <script type="math/tex">(x_{n(t)},y_{n(t)})</script></p>

<script type="math/tex; mode=display">sign(w_t^T x_{n(t)}) \neq y_{n(t)}</script>
  </li>
  <li>
    <p>(try to) correct the misstake by:</p>

<script type="math/tex; mode=display">w_{t+1} = w_{t} + y_{n(t)} x_{n(t)}</script>
  </li>
</ol>

<p>当问题是线性可分的时候，PLA可以保证算法收敛到一条合适的线,详细的证明可以参考video。当问题线性不可分时，需要对算法进行适当的修改，找到一条“合适”的曲线即可。</p>

<p>直观上理解PLA：如果机器犯了错误，当$y$实际上是+1, 说明$w_t$ 和 $x$的夹角超过90度，偏大。需要讲$w_t$向x的方向移动一个角度。
<script type="math/tex">w_{t+1}=w_t + x</script>, 反之$y$实际上是-1, 说明$w_t$ 和 $x$的夹角小于90度，偏小。需要讲$w_t$向x的反方向移动一个角度。 <script type="math/tex">w_{t+1}=w_t - x</script></p>

<p>线性分类器，是一个利用超平面来进行二分类的分类器，每次利用新的数据实例，预测，比对，更新，来调整超平面的位置。
相对于SVM，感知器不要每类数据与分类面的间隔最大化。</p>

<h3 id="average-perceptron">平均感知器(Average Perceptron)</h3>

<p>线性分类器，其学习的过程，与Perceptron感知器的基本相同，只不过，它将所有的训练过程中的权值都保留下来，然后，求均值。</p>

<p>优点：克服由于学习速率过大，所引起的训练过程中出现的震荡现象。即超平面围着一个中心，忽左忽右之类.</p>

<ol>
  <li>For t = 1,2,…n
    <ol>
      <li>对<script type="math/tex">(x_t,y_t)</script>,如果<script type="math/tex">sign(w_t^T x_{t}) \neq y_{t}</script>，计算<script type="math/tex">w_{t+1} = w_{t} + y_{t} x_{t}</script></li>
    </ol>
  </li>
  <li>输出 $\sum\limits_{i = 1}^n {\frac{w_i}{n}} $</li>
</ol>

<h3 id="passive-aggressive-perceptron">Passive Aggressive Perceptron:</h3>

<p>修正权值时，增加了一个参数$T_t$，预测正确时，不需要调整权值，预测错误时，主动调整权值。并可以加入松弛变量的概念，形成其算法的变种。</p>

<p>优点：能减少错误分类的数目，而且适用于不可分的噪声情况。</p>

<ol>
  <li>For t = 1,2,…n
    <ul>
      <li>对<script type="math/tex">(x_t,y_t)</script>,如果<script type="math/tex">sign(w_t^T x_{t}) \neq y_{t}</script></li>
      <li>$l_t = max \{0,1-y_t(w_t x_t) \}$</li>
      <li>计算<script type="math/tex">w_{t+1} = w_{t} + \tau_t y_{t} x_{t}</script></li>
    </ul>
  </li>
  <li>输出$w_n$</li>
</ol>

<p>根据 <script type="math/tex">\tau_t</script>的不同PAP变种为：</p>

<p>1.<script type="math/tex">\tau_t = \frac{l_t}{\|X_t\|^2}</script></p>

<p>2.<script type="math/tex">\tau_t =  min\{C, l_t / \|X_t\|^2\}</script></p>

<p>3.<script type="math/tex">\tau_t =  \frac{l_t}{\|X_t\|^2 + 1/(2C)}</script></p>

<h3 id="voted-perceptron">Voted Perceptron:</h3>

<p>存储和使用所有的错误的预测向量。</p>

<p>优点：实现对高维数据的分类，克服训练过程中的震荡，训练时间比SVM要好。</p>

<p>缺点：不能保证收敛</p>

<p><img src="http://wxwidget.github.io/images/VotedPerceptron.png" alt="vp" /></p>

<h3 id="confidence-weight">Confidence Weight：</h3>

<p>线性分类器，来之google ICML2008的论文.<a href="http://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/34667.pdf">Conﬁdence-Weighted Linear Classiﬁcation</a>,[videolectures]相关视频介绍(http://videolectures.net/icml08_pereira_cwl/)</p>

<p>每个学习参数都有个信任度（概率），信任度小的参数更应该学习，所以会得到更频繁的修改机会。信任度，用参数向量的高斯分布表示。</p>

<p>权值w符合高斯分布N(u, 离差阵)，而 由w*x的结果，可以预测其分类的结果。</p>

<p>并对高斯分布（的参数）进行更新。
<img src="http://wxwidget.github.io/images/cw.png" alt="cw" /></p>

<p>这种方法能提供分类的准确性，并加快学习速度。其理论依据在在于算法正确的预测概率不小于高斯分布的一个值。</p>

<h3 id="arow-adaptive-regularition-of-weighted-vector">AROW： adaptive regularition of weighted vector</h3>

<p>NIPS2009的论文<a href="http://books.nips.cc/papers/files/nips22/NIPS2009_0611.pdf">Adaptive Regularization of Weights</a>
<a href="https://code.google.com/p/arowpp/">code</a></p>

<p>具有的属性：大间隔训练large margin training，置信度权值confidence weight，处理不可分数据（噪声）non-separable</p>

<p>相对于SOP(second of Perceptron)，PA, CW, 在噪声情况下，其效果会更好.</p>

<p><img src="http://wxwidget.github.io/images/arow.png" alt="arow" /></p>

<h3 id="normal-herding">Normal herding：</h3>

<p>线性分类器</p>

<p>NHerd算法在计算全协方差阵和对角协方差阵时，比AROW更加的积极。</p>

<p><img src="http://wxwidget.github.io/images/nherd.png" alt="nherd" /></p>

<h3 id="ogd-">OGD 梯度法</h3>
<p><img src="http://wxwidget.github.io/images/ogd.png" alt="OGD" /></p>

<h3 id="weight-majority">Weight Majority:</h3>
<p>每个维度都可以作为一个分类器，进行预测；然后，依据权值，综合所有结果，给出一个最终的预测。</p>

<p>依据最终的预测和实际测量结果，调整各个维度的权值，即更新模型。</p>

<p>易于实施，错误界比较小，可推导。</p>

<p><img src="http://wxwidget.github.io/images/wm.png" alt="wm" /></p>

<h4 id="section-3">一点解释</h4>

<p>no-regret是不是很难达到呢？事实证明很多简单的算法都是no-regret。举个最经典的例子，假设我们有m个专家，他们在每轮问题都会给出的答案，假设答案就两种。损失函数是0-1损失函数，答案正确损失为0，否则为1. 先考虑最简单的情况：假设至少有一个完美专家，她永远给出正确的答案。那么什么才是learner的好策略呢？最简单的很work：看多数专家怎么说罗。 learner在时刻t先挑出前t-1轮一直是给正确答案的专家们，然后采用他们中多数人给出的那个答案。</p>

<p>记$C_t$是前t-1轮一直是给正确答案的专家们的集合，$|C_t|$是这些专家的个数。如果learner在时刻t给出了错误的答案，那么意味着$C_t$中大部分专家都给了错误答案，所以下一时刻learner参考的专家就会少一半。因为完美专家的存在，所以$|C_t|$不可能无限变小使得小于1，所以learner不能无限犯错。事实上，<script type="math/tex">C_t</script>至多有<script type="math/tex">\log_2(m)</script>次变小机会，所以learner最多有<script type="math/tex">\log_2(m)</script>的损失。另一方面，最优策略当然是一直选中一位完美专家，总损失为0，所以<script type="math/tex">R(T)\le \log_2(m)</script>，上界是个常数.</p>

<p>现在考虑并没有传说中的完美专家存在的情况。这时维护<script type="math/tex">C_t</script>的做法就不行了，我们使用一个稍复杂些的策略。记第i个专家为<script type="math/tex">e^i</script> ，对其维护一个信任度<script type="math/tex">w^i\in[0,1]</script>，且使得满足<script type="math/tex">\sum_{i=1}^m w^i=1</script>。记t时刻这m个信任度组成的向量是<script type="math/tex">w_t</script>，可以将其看成是关于这m专家上的一个分布，于是learner可以按这个分布来随机挑选一个专家，并用她的答案来做作为t时刻的答案。这意味着信任度高的专家被挑中的概率越高。</p>

<p>关键是在于如何调整<script type="math/tex">w_t</script>。直观上来说，对于在某一轮预测不正确的专家，我们需降低对她们的信任度，而对预测正确的，我们则可以更加的相信她们。一种常见的调整策略是基于指数的。我们先维护一个没有归一化（和不为1）的信任度u。一开始大家都为1，<script type="math/tex">u_0^i=1</script>. 在t时刻的一开始，我们根据i专家在上一轮的损失<script type="math/tex">\ell_{t-1}(e^i)</script>来做如下调整：</p>

<script type="math/tex; mode=display">
    u_{t}^i=u_{t-1}^i\exp(-\eta\ell_{t-1}(e^i))
</script>

<p><script type="math/tex">\eta</script>是学习率，越大则每次的调整幅度越大。然后再将<script type="math/tex">u_t</script>归一化来得到我们要的分布：<script type="math/tex">w_t^i=u_t^i/\sum_i u_t^i</script>。</p>

<p>基于指数的调整的好处在于快速的收敛率（它是强凸的），以及分析的简单性。我们有如下结论：如果选择学习率<script type="math/tex">\eta=\sqrt{8\ln m/T}</script>，那么<script type="math/tex">R(T)\le \sqrt{T\ln m/2}</script>。</p>

<p>一个值得讨论的问题是，设定最优学习率<script type="math/tex">\eta</script>需要知道数据的总个数T，而在实际的应用中也许不能知道样本到底会有多少。所以如果设定一个实际不错的参数很trick。在以后的算法中还会遇到这类需要上帝之手设定的参数，而如何使得算法对这类控制速率的参数不敏感，是当前研究的一个热点。这是后话了。</p>

<p>另外一个值得注意的是，同前面存在完美专家的情况相比，平均regret的上界由<script type="math/tex">\frac{\log_2 m}{T}</script>增到了<script type="math/tex">\sqrt{\frac{\ln m}{2T}}</script>。 这两者在实际的应用中有着很大差别。例如我们的目标是要使得平均regret达到某个数值以下，假设前一种方法取1,000个样本（迭代1,000次）就能到了，那么后一种算法就可能需要1,000,000个样本和迭代。这样，在时间或样本的要求上，前者明显优于后者。类似的区别在后面还会更多的遇到，这类算法的一个主要研究热点就是如何降低regret，提高收敛速度。</p>

<h2 id="section-4">在线凸优化</h2>

<!--http://mli7.wordpress.com/2011/04/08/online_learning_2/ -->

<h2 id="primal-dual">Primal-dual的观点</h2>

<p>天地间都赋阴阳二气所生</p>

<h2 id="section-5">算法举例</h2>

<ul>
  <li><a href="https://code.google.com/p/arowpp/">arowpp</a></li>
  <li><a href="https://code.google.com/p/oll/">oll</a></li>
  <li><a href="https://code.google.com/p/sofia-ml/">sofia-ml</a></li>
  <li><a href="http://www.cais.ntu.edu.sg/~chhoi/libol/">libol</a></li>
  <li><a href="https://github.com/jubatus/jubatus">jubatus</a></li>
  <li><a href="http://moa.cms.waikato.ac.nz/">moa</a></li>
</ul>

<h2 id="section-6">参考文献：</h2>
<ol>
  <li>N. Cesa-Bianchi, A. Conconi, and C. Gentile. A second-order perceptron algorithm.
SIAM J. Comput., 34(3):640–668, 2005</li>
  <li>K. Crammer, O. Dekel, J. Keshet, S. Shalev-Shwartz, and Y. Singer. Online passiveaggressive
algorithms. Journal of Machine Learning Research, 7:551–585, 2006.</li>
  <li>K. Crammer, M. Dredze, and A. Kulesza. Multi-class confidence weighted algorithms.
In EMNLP, pages 496–504, 2009.</li>
  <li>K. Crammer, M. Dredze, and F. Pereira. Exact convex confidence-weighted learning.
In NIPS, pages 345–352, 2008.</li>
  <li>K. Crammer, A. Kulesza, and M. Dredze. Adaptive regularization of weight vectors.
In NIPS, pages 414–422, 2009.</li>
  <li>K. Crammer, A. Kulesza, and M. Dredze. Adaptive regularization of weight vectors.
Machine Learning, 91(2):155–187, 2013.</li>
  <li>K. Crammer and D. D. Lee. Learning via gaussian herding. In NIPS, pages 451–459,
2010.</li>
  <li>K. Crammer and Y. Singer. Ultraconservative online algorithms for multiclass problems.
Journal of Machine Learning Research, 3:951–991, 2003.</li>
  <li>M. Fink, S. Shalev-Shwartz, Y. Singer, and S. Ullman. Online multiclass learning by
interclass hypothesis sharing. In Proceedings of the 25th International Conference
on Machine learning (ICML’06), pages 313–320, 2006.</li>
  <li>C. Gentile. A new approximate maximal margin classification algorithm. Journal
of Machine Learning Research, 2:213–242, 2001.</li>
  <li>Y. Li and P. M. Long. The relaxed online maximum margin algorithm. Machine
Learning, 46(1-3):361–387, 2002.</li>
  <li>F. Orabona and K. Crammer. New adaptive algorithms for online classification. In
NIPS, pages 1840–1848, 2010.</li>
  <li>F. Rosenblatt. The perceptron: A probabilistic model for information storage and
organization in the brain. Psych. Rev., 7:551–585, 1958.</li>
  <li>J. Wang, P. Zhao, and S. C. H. Hoi. Exact soft confidence-weighted learning. In
ICML, 2012.</li>
  <li>L. Yang, R. Jin, and J. Ye. Online learning by ellipsoid method. In ICML, page
145, 2009.</li>
  <li>P. Zhao, S. C. H. Hoi, and R. Jin. Double updating online learning. Journal of
Machine Learning Research, 12:1587–1615, 2011.</li>
  <li>P. Zhao, S. C. H. Hoi, R. Jin, and T. Yang. Online auc maximization. In ICML,
pages 233–240, 2011.</li>
  <li>M. Zinkevich. Online convex programming and generalized infinitesimal gradient
ascent. In ICML, pages 928–936, 2003.</li>
</ol>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Spare Classification RBM系统]]></title>
    <link href="http://wxwidget.github.io/blog/2013/12/30/spare-classification-rbm/"/>
    <updated>2013-12-30T11:21:00+08:00</updated>
    <id>http://wxwidget.github.io/blog/2013/12/30/spare-classification-rbm</id>
    <content type="html"><![CDATA[<h2 id="section">简介</h2>

<p>该系统通过对检索查询的相关特征进行有监督的学习从而得到在线广告推荐业务
的CTR预估模型。由于在线系统的训练数据量巨大（通常为数亿条），特征的维
度高，所以必须要考虑构建分布式的训练系统以降低大规模训练所需要的时间。
本文第二节介绍单进程Sparse Classification RBM的基本算法；第三节探讨采用
DownPour优化算法做多进程RBM Training开发的思路；第四节讨论要训练更大规
模的模型，进行优化的方向和基本实现方法；第四节讨论实现该系统所涉及到的
工程技术，包括开发语言，开发库等等。
TR预估模型。由于在线系统的训练数据量巨大（通常为数亿条），特征的维
度高，所以必须要考虑构建分布式的训练系统以降低大规模训练所需要的时间。
本文第二节介绍单进程Sparse Classification RBM的基本算法；第三节探讨采用
DownPour优化算法做多进程RBM Training开发的思路；第四节讨论要训练更大规
模的模型，进行优化的方向和基本实现方法；第四节讨论实现该系统所涉及到的
工程技术，包括开发语言，开发库等等。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[广告基础]]></title>
    <link href="http://wxwidget.github.io/blog/2013/12/12/ad-tech/"/>
    <updated>2013-12-12T14:20:00+08:00</updated>
    <id>http://wxwidget.github.io/blog/2013/12/12/ad-tech</id>
    <content type="html"><![CDATA[<!--more-->
<p>### 技术层面</p>

<ol>
  <li>Paper
    <ul>
      <li>雅虎研究院的publication。</li>
      <li>Google的publication： <a href="http://research.google.com/pubs/pub41159.html">Ad Click Prediction: a View from the Trenches</a>。该文探讨既有online训练特性，又能获得sparse模型的FTRL-Proximal算法。论文还阐述了很多实用技巧，包括给各个维度用上不同的学习率，用更少的bits去存储参数等。这个算法不单适用于对CTR问题的LR建模，也适合于其他使用online gradient descent方法的场景。</li>
    </ul>
  </li>
</ol>

<h3 id="section">业务层面</h3>

<ul>
  <li>精准广告定向
  一篇<a href="http://www.iamniu.com/2012/05/26/summary-internet-precise-ad-targeting-technology/?hmsr=top%20main%20content&amp;hmmd=&amp;hmpl=&amp;hmkw=&amp;hmci=">总结</a>，该文介绍了User-Agent、Cookie、各种定向技术和网络广告反作弊，并侧重在业务介绍。该文博主的<a href="http://www.iamniu.com/">首页</a></li>
  <li>在线展示广告
  在线展示广告的<a href="http://wayinwayout.com/%E5%9C%A8%E7%BA%BF%E5%B1%95%E7%A4%BA%E5%B9%BF%E5%91%8A%E7%9A%84%E8%BF%9B%E5%8C%96-evolution-online-display-advertising/">进化</a>，从Ad network谈到Ad Exchange（RTB）。</li>
</ul>

<h3 id="section-1">技术课程</h3>

<ol>
  <li><a href="http://study.163.com/course/courseMain.htm?courseId=321007#/courseMain">刘鹏计算广告学（video）</a></li>
  <li><a href="https://www.stanford.edu/class/msande239/">斯坦福大学的计算广告学（slide）</a></li>
  <li><a href="http://guanggaoxue.csdn.net/module/zone/baidu_data/index#video_course">百度的计算广告学（video）</a></li>
  <li><a href="http://ctech.baidu.com/?r=courses/content&amp;c_id=203&amp;qq-pf-to=pcqq.c2c">百度在清华大学开的计算广告学（slide）</a></li>
</ol>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[机器学习在个性化推荐中的应用]]></title>
    <link href="http://wxwidget.github.io/blog/2013/12/04/learning-to-recommendation/"/>
    <updated>2013-12-04T11:38:00+08:00</updated>
    <id>http://wxwidget.github.io/blog/2013/12/04/learning-to-recommendation</id>
    <content type="html"><![CDATA[<h2 id="section">引子</h2>

<ul>
  <li>受众: 技术杂志的读者，受过计算机教育但是领域比较泛。要求有简单的数学基础和机器学习的背景知识。</li>
  <li>主题：不讲机器学习算法是什么,讲学习算法如何和应用场景结合的问题</li>
  <li>逻辑: 发现问题-分析问题-解决问题</li>
</ul>

<!--more-->

<h2 id="section-1">正篇</h2>

<p>双11对消费者来说是一场空前的购物狂欢，对技术人员来说更像一场盛大的技术嘉年华。</p>

<p>2013年以前，天猫的推荐一直采用传统的协同过滤的启发式公式方法，特别是item based 方法，item based 算法在描述商品与商品相似度方面是非常优秀的，但是当我们遇到如下两个问题时，便捉襟见肘了：1) 当商品之间的关系可以由多个维度来描述，比如用户行为和文本相似性，如何来融合这些维度算法的权重？2) 当需要基于用户的实时数据（通常有数十个维度），预测用户的偏好，如何确定这些特征的权重？</p>

<p>今年，我们大量的采用了机器学习算法提升用户体验，有效的改善了当前的业务现状, 同时利用大数据的优势，产生了新的生产力。</p>

<p>在典型的业务场景中，机器学习主要用于购物链路的导购：</p>

<ul>
  <li>交易前类目品牌购买预测</li>
  <li>交易中相似和搭配购买推荐</li>
  <li>交易后回路引流</li>
</ul>

<p>在双11场景中,机器学习在预热期、活动中、活动结束后3个时间段发挥不同的作用。</p>

<ul>
  <li>在预热期主要用于引导用户关注品牌定制双11;引导将商品加入购物车和收藏夹加快购物效率;同时搜集用户购买意向，预测用户在类目和品牌的购买倾向。</li>
  <li>在活动中对用户进行个性化引导，一方面利用历史数据，算法学习出用户的偏好和意图，使得一进入天猫页面给与最直接的个性化冲击。比如在首页的个性化品牌，我的双11页面的品牌活动，无线会场的个性化等等。 另一方面，发挥集体智慧优势挖掘商品、品牌或者类目之间的关联关系，帮助用户寻找更合适的相似替换商品、提供更加合理的购买搭配。比如：在下架页的相似推荐，加入购物车后的搭配推荐。</li>
  <li>活动结束后，调整算法模型，平衡日常模型和活动模型的效果。即要剔除异常数据使得日常推荐体验不下降, 又要起到清尾货保证活动部分延续性的作用。</li>
</ul>

<p>可以看到机器学习应用的业务场景繁多, 业务目标不一样，算法的设计也会千差万别, 
因此，下面的内容不会涉及到全部的应用场景，而是通过两个基本的机器学习案例来讨论天猫是如何根据业务场景来设计机器学习算法的。
以下的文章结构安排如下：先讨论用户的偏好预测和在线点击率预估两个案例，然后综合两个案例介绍天猫如何应对大规模的机器学习的挑战。</p>

<h2 id="section-2">机器学习是如何工作的</h2>

<p>如何在复杂的场景中抓住算法设计的核心，是机器学习应用的主要挑战。 在应用层面上，业务目标决定算法形态。
比如当业务强调浏览深度的时候，算法上目标上就需要偏向与高质量的集合形式候选的推荐, 定义多维度的质量或者抽取提炼体现质量维度的特征等；
如果业务强调召回降低基尼系数，算法上要控制流量，在准确率和召回率之间找到业务平衡点，融入尾部优势的特征,调整正负样本比率和样本的权重等。</p>

<p>尽管业务变幻莫测, 我们还是能抽丝剥茧, 找到机器学习算法上的是抽象一致的本质。
天猫推荐在机器学习实践中使用的主要技术是：</p>

<ul>
  <li>分类/回归模型</li>
  <li>自动化参数</li>
  <li>多模型融合</li>
  <li>海量数据和分布式</li>
</ul>

<p>以例为证：</p>

<h3 id="section-3">用户的偏好预测</h3>

<p>电商领域的偏好一般是指用户长期积累起来的购物行为惯性。所以在预测偏好时，通常会选用大粒度,更抽象的维度去预测，
我们会在离线预测用户品牌和类目的购买偏好。类目偏好和品牌偏好类似，所以这里只以品牌偏好为例子。</p>

<ul>
  <li><strong>问题1</strong>：给定用户U和品牌列表L，从中选择N个品牌作为列表候选。 </li>
  <li><strong>问题2</strong>：给定用户U和品牌列表L，预测当天用户U对品牌B的产生行为的可能性。通常行为指的是点击、购买、收藏等</li>
</ul>

<p>如果假设用户对品牌的感知是独立的，那么<strong>问题1</strong>可以简化成TOPN的问题，<strong>问题2</strong>的TOPN解可以作为<strong>问题1</strong>的答案。
我们通过构造分类模型来预测用户对品牌的偏好程度，求解问题。</p>

<ul>
  <li>
    <p>数据。数据的真实性和充分性决定了算法的效果, 如何挑选数据是机器学习算法最重要的第一步。
在Netflix影视推荐中，可以用用户电影评分做预测。 在天猫业务中这种常用的显式表达的数据是缺失的,
我们只能利用隐式的用户行为推测偏好。一种方法是以用户对品牌产生行为的类型、次数和时间衰变映射到得分，然后再转化成评分预测问题。
另一种是直接预估行为(如:点击)的可能性，直接预测法在此场景中效果更好。</p>
  </li>
  <li>
    <p>模型。模型是算法的计算核心。对某个样例，如果X表示&lt;用户，品牌&gt;对，Y表示用户是否点击品牌。我们的基础模型是通过逻辑回归预测
用户对品牌的点击可能性，<a href="http://en.wikipedia.org/wiki/Logistic_regression">逻辑回归</a>的基本假设是：</p>
  </li>
</ul>

<script type="math/tex; mode=display"> 
p = P(Y=1 | X=x)= \frac{1}{1+e^{-(w_0 + w x)}}
</script>

<p>其中w是的模型的参数，它的解是：</p>

<script type="math/tex; mode=display">
w = \arg {\max _w}P(Y|X;w) = \arg {\max _w}\prod\limits_{i = 1}^N {P({y_i}|{x_i};w)} 
</script>

<p>实际过程中我们转化成标准型，加入L1，L2正则化之后求解。
考虑到逻辑回归归根结底是广义的线性模型，而实际的数据分布是非常复杂的非线性关系。我们采用了一些非线性的方法，
比如对特征非线性离散化，条件组合, 有限核变换等等，这些方法需要对数据有正确的认识才能取得好的效果。
同时也会采用非线性模型的方法，在阿里集团中混合逻辑回归是最常见的方法，该方法是Mixture of expert的一种简单变种，
这方面的资料非常丰富，这里就不再展开。</p>

<ul>
  <li>特征。在特征层面，按用途上分成两种，一种是warm-start特征，解决数据充分时候准确的问题。主要是品牌id，用户id。
另一种cold-start特征，解决用户数据缺失、品牌数据缺失的问题。这些特征通常是集合性特征，比如品牌的主题内容，类目, 用户等级等等。
从从属上看，特征分析全局特征，用户特征，品牌特征，用户品牌关联特征, 其中用户品牌关联特征起关键的作用。有一些特征是专门设计过的，比如正对用户等级比较高，购买能力比较强的用户会和品牌的档次结合组合成特征；对冲着折扣找便宜的用户，折扣力度和热门程度一起也会形成组合特征;考虑业务本身的特征，我们不希望热门的品牌局部过热导致基尼系数过高和客服服务质量的下降, 此时我们会更突出个性化, 引入用户权重和品牌权重。</li>
</ul>

<p>当然,没有万能的模型，不论是朴素逻辑回归模型还是混合逻辑归回模型，都会有它的缺点。
逻辑回归对高维非线性数据不理想，混合逻辑回归区域划分参数过度敏感容易过拟合。
在个性化实践中也Learning To Rank也应用比较广泛。在品牌偏好计算中，通常不关心具体的数值大小，
更加关心的是相对的偏好关系。Pairwise的学习方式，把浏览，点击，收藏，加入购车，购买等用户行为用偏序关系连接在一起，个性化程度也更强;
同时，为了是算法即拟合双11的突变性又延续日常的模型, 我们以日常模型为先验, 训练双11的模型，采用了双模型加权的方法。</p>

<p>品牌偏好对应的业务场景非常多, 但是大致分成情感化连接和新颖性发现两个部分。用户品牌偏好只解决了情感化连接的部分，我们同样也会通过挖掘品牌和品牌之间的联系, 让用户发现新品牌，算法会预测用户对新品牌的偏好程度，提高惊喜度。</p>

<h3 id="section-4">在线点击率预估</h3>

<p>通常用户对推荐结果的点击行为是衡量推荐结果质量的重要指标之一, 在推荐中会直接预估用户的对推荐候选的点击率。
我们根据应用场景，把点击率预估可以分成两个部分。</p>

<ul>
  <li>离线点击率预估。离线部分是数据层面上的复用, 可用于快速业务接入和系统低延时的响应。</li>
  <li>在线点击率预估。在线部分是模型层面上的复用, 用于更精准的用户个性化。</li>
</ul>

<p>核心算法和<strong>用户偏好预测</strong>基本上一致，不同的是在线点击率预估结合实时和历史的数据，
机器学习已经不是纯算法问题，已经演变成算法系统。本节将忽略算法的细节，重点是讲述商品在线点击率预估的算法架构。</p>

<p><img src="http://wxwidget.github.io/images/recommender.png" alt="推荐系统结构图" /></p>

<p>(这张图重新画下，注意只要一个框架图，不能太过具体)</p>

<p>系统流程是：</p>

<ol>
  <li>用户通过业务层发送请求</li>
  <li>推荐服务请求用户引擎获取用户特征。包括一下几件事：
    <ul>
      <li>计算实时意图, 计算用户实时类目、品牌、标签等偏好等等</li>
      <li>页面场景分析，来源页和当前页的上下文情景等等</li>
      <li>获取用户历史偏好：包括人物画像，历史行为记录，内容标签等等</li>
      <li>预测用户心智和状态</li>
    </ul>
  </li>
  <li>推荐引擎合成检索请求并获取推荐候选列表, 此时候选列表通过离线计算粗排基本有序</li>
  <li>获取候选用户特征和商品特征，按需做组合和变换等操作, 生成最终模型特征</li>
  <li>计算引擎根据模型预估点击率，对结果排序。模型分两个部分：
    <ul>
      <li>离线学习的模型, 按天更新模型,适用相对稳定的场景。 </li>
      <li>在线学习在研发阶段, 实时更新,适用变化比较快的场景。</li>
    </ul>
  </li>
  <li>推荐引擎对结果再加工，投送到目标资源位。主要的加工包括：
    <ul>
      <li>低质量候选过滤。</li>
      <li>多样性控制</li>
      <li>时效性混新</li>
      <li>探索和开发</li>
      <li>业务逻辑混入等等</li>
    </ul>
  </li>
</ol>

<p>可以看到机器学习算法作为一个算法系统在整个推荐系统发挥重要的作用。
从理解用户意图、预测用户的行为、实体关联网络挖掘到
综合所有因子给用户推荐最合适的候选的排序,
再到不同质候选混合，多逻辑混排, 跨终端推荐,…, 
机器学习深入各各环节。</p>

<h2 id="section-5">总结</h2>

<p>通过以上两个案例，大致了解和算法计算框架和系统骨架, 但是绝对不是机器学习应用的全部。
在个性化推荐实践中面临巨大的挑战, 还需要不断的实践和探索. 比如：</p>

<ul>
  <li>目标上：提供多准则推荐算法, 支持多维度的评价指标; 实质性提升用户体验，提供更加有弹性和甚至不打扰的结果。</li>
  <li>特征上：结合上下文信息, 深化对用户和候选的理解;利用更多的外围数据，建立实体知识体系;面对动态数据，捕捉用户意图漂移和商品的生命演化。</li>
  <li>模型上：尝试新的非线性算法模型，从不同的维度训练算法模型，利用各模型的优点组合新算法。</li>
  <li>规模上：面对的是不断增长的海量数据，亿级的特征，开发快速高效的大规模和伸缩性并发算法。</li>
  <li>工程上: 推荐系统是一个非常复杂的系统，机器学习算法需要结合复杂系统, 融入到系统中提供高效稳定的结果。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[合约投放系统-介绍]]></title>
    <link href="http://wxwidget.github.io/blog/2013/12/03/guaranteed-delivery/"/>
    <updated>2013-12-03T17:28:00+08:00</updated>
    <id>http://wxwidget.github.io/blog/2013/12/03/guaranteed-delivery</id>
    <content type="html"><![CDATA[<h2 id="section">合约投放系统</h2>

<h3 id="section-1">直接媒体购买</h3>

<p>合约广告英文是Agreement-based Advertising，它是一种基于合约(Agreement)的商业模式，大家会看到它与Network和Exchange有相当大的不同，我们当前最主要的是把合约广告要解决的问题理解清楚，具体的技术可以再理解。</p>

<p>传统的广告媒体购买方式是称之为直接媒体购买方式(Direct Media Buy)。
它是一种简单的购买方式，比如一个杂志可能有几个广告位，比如封二页，封底页，广告主可以直接购买这些广告位，这种方式没有任何的技术元素。在这种方式的运作中，Supply有一个广告排期系统，广告排期系统比较简单，用于对购买了的广告位，以及相应的时间的广告排期。不提供受众定向，它在展示时将广告素材直接插入页面，这样广告作为静态资源加载，它的response time就会比较短，这样用户看到广告也越早，效果也就也越好。这种方式的代表公司是4A。需求方，即广告代理商要做的是两件事情：</p>

<ol>
  <li>帮助广告商策划和执行排期，</li>
  <li>用经验和人工满足广告商的质和量的需求。</li>
</ol>

<p>比如宝马公司今年要reach多少用户，通过什么要的媒体reach，4A公司就会帮宝马公司把创意做好，并分析在哪些媒体，哪些位置上投放广告，能达到效果。因为没有技术元素，所以都是要依赖经验和人工的方式来完成的。但令人惊讶的是，中国很多品牌广告仍然是以为种方式进行的。</p>

<!--more-->

<h3 id="section-2">担保式投送</h3>

<p>在线广告的一种主流做法是担保式投送（Guaranteed Delivery, GD），这种方法与广告位的直接购买不同的是：<em>从媒体角度是它卖的不是广告位，而是广告位上的流量</em>。从Yahoo!来看，它的逻辑是这样的：最早开放出一个广告位，每隔一段时间会提高这个广告位的售价，但涨到一定的售价后，就很难再涨了，它就将广告位的流量拆开，比如分为男性用户流量和女性用户流量，比如一个广告位整体出售可能价值1万元，但男性用户流量可能最高能卖7000元，女性用户流量假设价值6000元，那么总售价是13000，比整体出售的售价10000元的收益要高。为什么说它还是一个合约机制呢？是因为广告主和媒体所签的协议中还有明确的量的需求，我们在讨论品牌广告和效果广告时提到过，量（Quantity）和质（Quality）是广告主的两个根本需求，这两个需求是固有的，只是可能侧重点有时候会不同。在GD广告中，量是在合约中明确写明的，比如合约中如果写了要对加州男性的用户进行100万次的展示，如果没有完成这100万次的展示，是需要广告平台根据所未完成的量进行较多的赔偿。</p>

<p>GD是一个量优先于质的销售方式，后面所讲的AdNetwork和AdExchange是质优先于量的销售方式，竞价系统的方式不同于GD，比如广告出0.5元买加州男性的用户流量，系统只会把当你的出价在所有竞争对手中是最高的时候，才分配给你，所以没有办法保证提供给你的流量。GD广告多采用千次展示付费（CPM）方式结算，多是品牌广告主使用GD，广告主的数量不多，Yahoo!也仅有1000～2000的广告主，但这些广告主的所签的都是大订单，它是合约广告最主要的市场形状。</p>

<p>不同于前面所提到的静态插入页面的方式，GD广告是在广告投放机（Ad server）上决策展示某个广告。受众定向，CTR预测，流量预测是GD广告投放机的基础。GD系统往往希望帮助广告商做一些优化，比如有的广告商买了加州男性用户，有的广告商买的财经类型用户，比如一个用户是加州男性财经用户，这个用户在访问时，Ad server会决定这次展示出什么广告。Ad Server的准则是希望把每个用户在满足多个合约的时候投给合适的广告商，以使得每个广告商的效果最好，这里相比AdNetwork有一个难点是GD必须满足合约里签定的给广告主的流量 。</p>

<h4 id="section-3">特点</h4>

<ul>
  <li>基于合约的广告机制，约定的量未完成需要向需求方补偿</li>
  <li>量优于质的销售模型</li>
  <li>多采用千次展示付费(Cost Per Mile, CPM)方式结算</li>
</ul>

<h4 id="section-4">投放机</h4>

<ul>
  <li>CPM方式收费必要要求投放在服务器端完成</li>
  <li>受众定向，CTR预估和浏览预测是投放机的基础</li>
  <li>GD合约下，投放机满足各合约的量，并且尽可能的优化需求方的质</li>
</ul>

<h3 id="section-5">系统结构</h3>

<p><img src="http://wxwidget.github.io/images/ad_gd.jpg" alt="GD" /></p>

<p>它有retrieval部分，retrieval部分是各个系统都存在的。
ranking的部分，它可能不是真正的ranking，有可能是做CTR预测。
上图没有画出来的部分是离线的forecasting，它对实际的GD系统非常重要，它会与Online Allocation模板配合。
反作弊和计价这是必须有的模块。而Real Time Index概念就不同了，合约广告系统中，它是用来对流量实时反馈。</p>

<h2 id="section-6">算法</h2>

<p><a href="http://wxwidget.github.io/paper/high_water_mark算法.pdf">High_Water_Mark算法</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[30天学30种技术[转]]]></title>
    <link href="http://wxwidget.github.io/blog/2013/12/03/learning-30-technologies-in-30-days-a-developer-challenge/"/>
    <updated>2013-12-03T13:31:00+08:00</updated>
    <id>http://wxwidget.github.io/blog/2013/12/03/learning-30-technologies-in-30-days-a-developer-challenge</id>
    <content type="html"><![CDATA[<h3 id="httpgeekcsdnnetnewsdetail3740"><a href="http://geek.csdn.net/news/detail/3740">30天学30种技术</a></h3>

<p>RedHat负责OpenShift技术推广的Shekhar Gulati从2013年10月29日开始，立下心愿要在<a href="https://www.openshift.com/blogs/learning-30-technologies-in-30-days-a-developer-challenge">30天内学习30种技术</a></p>

<p>现在，他完成了。他自己的头衔也编程了“30天学30种技术”博客作者，比Evangelist感觉的确强不少。这个系列当然也为OpenShift网站带来了不少流量和关注度。国内做技术营销的同学，学着点吧。</p>

<!--more-->

<p>这30天里，他学习了从前端到服务器，还有一些算法库。应该说，他对技术的选择眼光不错，其中除了少数是为OpenShift做宣传之外，多是现在值得关注的技术新贵。如果其中哪种技术属于你的领域，你还没听说过的话，应该看一看了。Gulati为每种技术都写下了一些学习心得，虽然不是大深入，但对粗略了解还是有价值的。</p>

<h3 id="section">这30种技术分别是：</h3>

<ul>
  <li>Bower：客户端依赖管理工具，由Twitter开源。</li>
  <li>AngularJS：来自Google的单页Web应用框架。</li>
  <li>Flask：近年来非常火的Python Web微框架。</li>
  <li>PredictionIO：基于Apache Mahout的开源机器学习服务器，用Scala开发。</li>
  <li>GruntJS：JavaScript世界里的命令行构建工具，类似make或者ant。</li>
  <li>Grails：这个不算新了，Groovy语言的Rails。</li>
  <li>GruntJS LiveReload：GruntJS的更高级应用。</li>
  <li>Harp：内置预处理的静态Web服务器，无需配置。</li>
  <li>TextBlob：开源Python文本处理库。</li>
  <li>PhoneGap——Mobile Development for the Dummies</li>
  <li>AeroGear Push Server——Push Notifications Made Easy</li>
  <li>OpenCV——Face Detection for Java Developers</li>
  <li>DropWizard——The Awesome Java REST Server Stack</li>
  <li>Stanford NER——How To Setup Your Own Name, Entity, and Recognition Server in the Cloud</li>
  <li>Meteor——Building a Web App From Scratch in Meteor</li>
  <li>Goose Extractor——An Article Extractor That Just Works</li>
  <li>JBoss Forge——Build and Deploy Java EE 6 AngularJS Applications using JBoss Forge and OpenShift</li>
  <li>BoilerPipe——Article Extraction for Java Developers</li>
  <li>Ember——The Missing EmberJS Tutorial</li>
  <li>Stanford CoreNLP——Performing Sentiment Analysis of Twitter using Java</li>
  <li>Docker——The Missing Tutorial</li>
  <li>Developing Single Page Applications with Spring, MongoDB, and AngularJS</li>
  <li>TimelineJS —— Build Beautiful Timelines</li>
  <li>Yeoman Ember——The Missing Tutorial</li>
  <li>Tornado——Combining Tornado, MongoDB, and AngularJS to Build an App</li>
  <li>TogetherJS——Let’s Code Together</li>
  <li>Restify——Build Correct REST Web Services in Node.js</li>
  <li>OpenShift Eclipse Integration for Java Developers</li>
  <li>Yeoman Chrome Generator——Write Your First Google Chrome Extension</li>
  <li>Play Framework——A Java Developer Dream Framework</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[mixture-of-expert]]></title>
    <link href="http://wxwidget.github.io/blog/2013/11/28/mixture-of-expert/"/>
    <updated>2013-11-28T16:59:00+08:00</updated>
    <id>http://wxwidget.github.io/blog/2013/11/28/mixture-of-expert</id>
    <content type="html"><![CDATA[<h2 id="section">算法描述</h2>

<h2 id="section-1">应用场景</h2>

<h2 id="section-2">优缺点</h2>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[相关性反馈-relevance feedback]]></title>
    <link href="http://wxwidget.github.io/blog/2013/11/28/recommender-relevance-feedback/"/>
    <updated>2013-11-28T16:54:00+08:00</updated>
    <id>http://wxwidget.github.io/blog/2013/11/28/recommender-relevance-feedback</id>
    <content type="html"><![CDATA[<h2 id="section">问题</h2>

<h3 id="section-1">场景</h3>

<h2 id="section-2">相关反馈</h2>

<h2 id="section-3">方法</h2>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CTR Prediction 3.0]]></title>
    <link href="http://wxwidget.github.io/blog/2013/11/22/ctr-prediction-v3/"/>
    <updated>2013-11-22T10:47:00+08:00</updated>
    <id>http://wxwidget.github.io/blog/2013/11/22/ctr-prediction-v3</id>
    <content type="html"><![CDATA[<h2 id="section">现状</h2>

<ul>
  <li>1.0的版本解决了离线算法融合的问题，所用的特征全部是离线计算的特征，和用户没有任何关系。在“i2i”场景中，得到充分的利用；</li>
  <li>2.0的版本解决了部分在线预估的问题,除了离线用户无关特征外，加入了用户画像特征，在线的用户意图分析和实时场景预测</li>
</ul>

<!--more-->

<h2 id="section-1">算法模型</h2>

<p>算法上采用LR直接预测用户对候选商品的点击可能性(或者rating)</p>

<h3 id="section-2">特征列表</h3>

<h4 id="section-3">相似特征</h4>

<p>相似推荐中涉及到两个相似的实体：A，B。因此计算考虑点击特征的时候会使用商品的相似特征, 这些特征从单一维度上都可以作为
推荐排序来使用，把这些特征合并在一起同时也起到了模型融合的作用。
同时，在特征中加入了rank特征，即用当前相似性排序时的排序位置。这样可以保证在加入额外特征的时候AUC指标不下降</p>

<ol>
  <li>jacard同店看了看相似度和rank:, rank最大为20,排在20以外的丢弃</li>
  <li>jacard同店买了买相似度和rank:</li>
  <li>cos同店同类看了看和rank:</li>
  <li>cos同店同类买了买和rank:</li>
  <li>同店同类看了买:v1,v2中使用</li>
  <li>同店同类买了看:未使用</li>
  <li>主商品和推荐商品是否为同类目商品</li>
</ol>

<p>说明：数值类特征采用截断分位数后的归一化，(x-min)/(max-min); log后还未用转换为类目相对销量的方式</p>

<h4 id="section-4">商品特征</h4>

<ol>
  <li>人气分： 属于销量预测模型，同时也是搜索的一个重要排序因子</li>
  <li>listctr：统计在list页上的点击率</li>
  <li>cvr：统计的商品pv转化率</li>
  <li>ixx: 行业id</li>
  <li>lxx：叶子类目</li>
  <li>sxx: 店铺id</li>
  <li>归一化推荐商品价格</li>
  <li>归一化推荐商品和主商品价格差</li>
  <li>log(1+周销量) //其中的一种power law的非线性变化方式</li>
  <li>log(1+周成交额)</li>
  <li>log(1+月销量)</li>
  <li>log(1+月成交额)</li>
</ol>

<h4 id="section-5">用户特征</h4>

<p>用户特征在这一期里还没有应用，后续其实可以加入更多的的用户画像、偏好、和意图的特征</p>

<h4 id="section-6">场景特征</h4>

<p>目前没有场景相关的特征，以后对页面的场景，比如在会场页，wap页、售后页，来源页等做适当特征分析
时间、状态（wap和pc）、天气、地点</p>

<h3 id="section-7">特征权重</h3>

<p><img /></p>

<h2 id="section-8">改进点</h2>

<p>有一些改进的方向：</p>

<ol>
  <li>新特征的引入：在常用的i2i场景中，引入人的因素，可以使得推荐的结果效果千人千面</li>
  <li>特征的变换：目前的模型特征线性的部分居多，如何能把特征从线性特征变成非线性的特征，比如对数化，离散化等等。类似svm的特征非线性变换方式</li>
  <li>新模型的探索：LR模型有其天然的局限性，对MOE(mixture of expert)的方法：比如MLR,Tree LR,DT,都可以尝试</li>
  <li>外围分析的方法的建设：
    <ol>
      <li>比如特征权重的分析</li>
      <li>特征重要度的分析</li>
      <li>交叉模型的回归分析</li>
      <li>可视化体验等等</li>
    </ol>
  </li>
  <li>L2R方法的探索：不需要准确预估值，直接预估偏好关系。(L2R方法比直接CTR的方法的优势不是特别明显，在什么业务场景适用L2R还需要进一步探索)</li>
</ol>

<h3 id="section-9">模型改进</h3>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[实时推荐]]></title>
    <link href="http://wxwidget.github.io/blog/2013/11/18/realtime-recommender/"/>
    <updated>2013-11-18T16:25:00+08:00</updated>
    <id>http://wxwidget.github.io/blog/2013/11/18/realtime-recommender</id>
    <content type="html"><![CDATA[<h2 id="section">为什么要实时</h2>
<ol>
  <li>每天新发布</li>
  <li>每天修改的商品</li>
  <li>各种换季、打折、促销、新款、活动</li>
  <li>突发事件</li>
  <li>新增加用户</li>
  <li>用户兴趣漂移</li>
</ol>

<p>长尾商品更多的曝光机会
流量动态利用</p>

<p>TIP: 提供一些数据支持，iPV/IPV</p>

<!--more-->

<h3 id="section-1">用户需求</h3>

<p>用户逛的调研:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">需求的强度</th>
      <th style="text-align: left">占比</th>
      <th style="text-align: left">解释</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">没有购物需求</td>
      <td style="text-align: left">2.2%</td>
      <td style="text-align: left">没事就逛逛</td>
    </tr>
    <tr>
      <td style="text-align: left">想购物还不知道买什么</td>
      <td style="text-align: left">27.2%</td>
      <td style="text-align: left">看看有没有什么划算的</td>
    </tr>
    <tr>
      <td style="text-align: left">想买某类东西，还不明确</td>
      <td style="text-align: left">53.9%</td>
      <td style="text-align: left">好像缺什么东西就逛逛</td>
    </tr>
    <tr>
      <td style="text-align: left">有明确想买的商品</td>
      <td style="text-align: left">16.0%</td>
      <td style="text-align: left">确定想买东西,先搜索</td>
    </tr>
  </tbody>
</table>

<h2 id="section-2">多快才是实时</h2>

<h2 id="section-3">实时推荐的作用</h2>

<h2 id="section-4">系统架构</h2>

<h2 id="section-5">算法实现</h2>

<h3 id="section-6">分类</h3>

<h3 id="section-7">聚类</h3>

<h3 id="section-8">频繁项集</h3>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Pegasos算法]]></title>
    <link href="http://wxwidget.github.io/blog/2013/11/14/svm-pegasos/"/>
    <updated>2013-11-14T11:49:00+08:00</updated>
    <id>http://wxwidget.github.io/blog/2013/11/14/svm-pegasos</id>
    <content type="html"><![CDATA[<p>本文参考了博文<a href="http://mark.reid.name/sap/online-learning-in-clojure.html">Online Learning in Clojure</a>和论文<a href="http://www.machinelearning.org/proceedings/icml2007/abstracts/587.htm">Pegasos: Primal Estimated sub-GrAdient SOlver for SVM</a>(<a href="http://www.machinelearning.org/proceedings/icml2007/papers/587.pdf">PDF</a>)</p>

<h2 id="online-learning">online learning</h2>

<p>Online learning的算法结构是非常简单的，下面的描述是监督的online learning算法框架，其中有经验损失函数$L$，样本流$S$，样本的格式为$(x,y)$:</p>

<pre><code>Initialise a starting model w
While there are more examples in S
    Get the next feature vector x
    Predict the label y' for x using the model w
    Get the true label y for x and incur a penaly L(y,y')
    Update the model w if y ≠ y'
</code></pre>

<p>一般来是，训练出来的模型都是一个与样本相同维度的向量。对应二分的分类器，往往涉及到的是计算内积$\langle w,x \rangle$，模型的更新是沿着损失函数的梯度下降方向的。</p>

<h2 id="pegasos">Pegasos</h2>

<p>论文<a href="http://www.machinelearning.org/proceedings/icml2007/abstracts/587.htm">Pegasos: Primal Estimated sub-GrAdient SOlver for SVM</a>是一种svm的online learning算法。</p>

<!-- more -->

<p>首先来看svm的经验损失函数：</p>

<script type="math/tex; mode=display">
\begin{array}{l}
L(w,S) = \frac{\lambda }{2}{\left\| w \right\|^2} + \frac{1}{k}\sum\limits_{(x,y) \in S} {h(w;(x,y))} \\
h(w;(x,y)) = \max \{ 0,1 - y \langle w,x \rangle \} 
\end{array}
</script>

<p>上面式子中，$k$是训练集$S$的大小，$h()$是the hinge loss（合页损失函数），$\langle w, x\rangle$表示$w,x$的内积，$\lambda$是正则化项。</p>

<p>在<a href="http://book.douban.com/subject/10590856/">《统计学习方法》</a>这本书的7.2.4证明了合页损失函数与引入松弛变量后的损失函数是等价的，并证明了$\lambda$与惩罚系数$C$是成反比的。引入松弛变量后的损失函数为:</p>

<script type="math/tex; mode=display">
\frac{1}{2}\left \| w \right \|^{2} + C\sum_{i=1}^{N}\xi _{i}
</script>

<p>训练过程中，如果遇到了一个预测错误的样本$(x,y)$, 对模型的更新方法如下：</p>

<script type="math/tex; mode=display">
{w_{t + \frac{1}{2}}} = (1 - \frac{1}{t}){w_t} + \frac{1} { {\lambda t} } yx
</script>

<p>其中$t$表示已经训练过的样本个数，$ {w_{t + \frac{1}{2}}}$表示训练过$t$个的样本后的模型，${w_{t + \frac{1}{2} }}$ 表示新模型。
根据pegasos算法，新模型的$l_2$范数如果超出了以 $\frac{1}{ {\sqrt \lambda  } }$ 为半径的超球面，那么需要将新模型投射到这个超球面上。即：</p>

<script type="math/tex; mode=display">
{w_{t + 1}} = \min \{ 1,\frac{1}{ {\sqrt \lambda  \left\| { {w_{t + \frac{1}{2} } } } \right\|}}\} {w_{t + \frac{1}{2}}}
</script>

<p>为什么需要将新的模型投射到以$\frac{1}{ {\sqrt \lambda  } }$为半径的超球面上呢？论文证明了svm的最优解是在下面这个集合中的：</p>

<script type="math/tex; mode=display">
B = \{ w:\left\| w \right\| \le \frac{1}{ {\sqrt \lambda  } }\} 
</script>

<p>而且在pegasos算法的推导，以及模型初始化$w$的时候，都使用了条件</p>

<script type="math/tex; mode=display">
\left\| w \right\| \le \frac{1}{ {\sqrt \lambda  } }
</script>

<p>由上面模型的更新公式可以简单分析一下正则化参数$\lambda$的作用，它决定了训练过程中，后面出现的预测错误的样本，对应模型的修正程度。$\lambda$越大，修正程度越小，$\lambda$越小，修正程度越大。同时$\lambda$与惩罚系数$C$是成反比的，所以也可理解为，在训练过称中，出现预测错误样本时，对模型的惩罚程度。$\lambda$越大，惩罚越小，$\lambda$越小，惩罚越大。</p>

<p>Pegasos的算法描述在论文”Pegasos: Primal Estimated sub-GrAdient SOlver for SVM”也是给出了的，可以参考。</p>

<p>但实际上pegasos是一个线性的svm，而且还是一个没有bias的svm，训练出来的线性函数是$y=\langle w,x \rangle$，在上面的论文中的Extensions小节中也讲到了，目前pegasos还没有证明可应用于线性模型$y=\langle w,x \rangle + b$或者是非线性svm模型。</p>

<h2 id="pegasos-1">Pegasos的实现例子</h2>

<p>实现了一个基于SMO算法的svm，今天就来基于Pegasos实现数字手写识别。svm用于多分类，还是一对多的方式，手写数据还是来自<a href="http://www.manning.com/pharrington/">“Machine Learning in Action”</a>的第二章的数据。下面是实现代码</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>基于pegasos的数字手写识别  (pegasos.py)</span> <a href="http://wxwidget.github.io/code/2013/pegasos/pegasos.py">download</a></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
<span class="line-number">29</span>
<span class="line-number">30</span>
<span class="line-number">31</span>
<span class="line-number">32</span>
<span class="line-number">33</span>
<span class="line-number">34</span>
<span class="line-number">35</span>
<span class="line-number">36</span>
<span class="line-number">37</span>
<span class="line-number">38</span>
<span class="line-number">39</span>
<span class="line-number">40</span>
<span class="line-number">41</span>
<span class="line-number">42</span>
<span class="line-number">43</span>
<span class="line-number">44</span>
<span class="line-number">45</span>
<span class="line-number">46</span>
<span class="line-number">47</span>
<span class="line-number">48</span>
<span class="line-number">49</span>
<span class="line-number">50</span>
<span class="line-number">51</span>
<span class="line-number">52</span>
<span class="line-number">53</span>
<span class="line-number">54</span>
<span class="line-number">55</span>
<span class="line-number">56</span>
<span class="line-number">57</span>
<span class="line-number">58</span>
<span class="line-number">59</span>
<span class="line-number">60</span>
<span class="line-number">61</span>
<span class="line-number">62</span>
<span class="line-number">63</span>
<span class="line-number">64</span>
<span class="line-number">65</span>
<span class="line-number">66</span>
<span class="line-number">67</span>
<span class="line-number">68</span>
<span class="line-number">69</span>
<span class="line-number">70</span>
<span class="line-number">71</span>
<span class="line-number">72</span>
<span class="line-number">73</span>
<span class="line-number">74</span>
<span class="line-number">75</span>
<span class="line-number">76</span>
<span class="line-number">77</span>
<span class="line-number">78</span>
<span class="line-number">79</span>
<span class="line-number">80</span>
<span class="line-number">81</span>
<span class="line-number">82</span>
<span class="line-number">83</span>
<span class="line-number">84</span>
<span class="line-number">85</span>
<span class="line-number">86</span>
<span class="line-number">87</span>
<span class="line-number">88</span>
<span class="line-number">89</span>
<span class="line-number">90</span>
<span class="line-number">91</span>
<span class="line-number">92</span>
<span class="line-number">93</span>
<span class="line-number">94</span>
<span class="line-number">95</span>
<span class="line-number">96</span>
<span class="line-number">97</span>
<span class="line-number">98</span>
<span class="line-number">99</span>
<span class="line-number">100</span>
<span class="line-number">101</span>
<span class="line-number">102</span>
<span class="line-number">103</span>
<span class="line-number">104</span>
<span class="line-number">105</span>
<span class="line-number">106</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="c">#!/usr/bin/env python</span>
</span><span class="line"><span class="c"># -*- coding: utf-8 -*-</span>
</span><span class="line">
</span><span class="line"><span class="c"># Pegasos implemented in Python</span>
</span><span class="line">
</span><span class="line"><span class="kn">import</span> <span class="nn">os</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">sys</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">math</span>
</span><span class="line">
</span><span class="line"><span class="n">G_WEIGHT</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">parse_image</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
</span><span class="line">    <span class="n">img_map</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class="line">    <span class="n">fp</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s">&quot;r&quot;</span><span class="p">)</span>
</span><span class="line">    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">fp</span><span class="p">:</span>
</span><span class="line">        <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
</span><span class="line">        <span class="k">for</span> <span class="n">ch</span> <span class="ow">in</span> <span class="n">line</span><span class="p">:</span>
</span><span class="line">            <span class="n">img_map</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">ch</span><span class="p">))</span>
</span><span class="line">    <span class="k">return</span> <span class="n">img_map</span>
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
</span><span class="line">    <span class="n">ret</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class="line">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">32</span><span class="o">*</span><span class="mi">32</span><span class="p">):</span>
</span><span class="line">        <span class="n">ret</span> <span class="o">+=</span> <span class="n">model</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span class="line">    <span class="k">return</span> <span class="n">ret</span>
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">train_one_model</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">sampleNum</span><span class="p">,</span> <span class="n">modelNum</span><span class="p">):</span>
</span><span class="line">    <span class="n">pvalue</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">G_WEIGHT</span><span class="p">[</span><span class="n">modelNum</span><span class="p">],</span> <span class="n">data</span><span class="p">)</span>
</span><span class="line">    <span class="c"># the hinge loss</span>
</span><span class="line">    <span class="k">if</span> <span class="n">pvalue</span> <span class="o">*</span> <span class="n">label</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
</span><span class="line">        <span class="k">return</span>
</span><span class="line">
</span><span class="line">    <span class="c"># update model</span>
</span><span class="line">    <span class="n">lambd</span> <span class="o">=</span> <span class="mf">0.5</span>
</span><span class="line">    <span class="n">new_weight</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class="line">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">32</span><span class="o">*</span><span class="mi">32</span><span class="p">):</span>
</span><span class="line">        <span class="c"># pegasos</span>
</span><span class="line">        <span class="n">a</span> <span class="o">=</span> <span class="n">G_WEIGHT</span><span class="p">[</span><span class="n">modelNum</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span> <span class="mi">1</span> <span class="o">-</span> <span class="mf">1.0</span><span class="o">/</span><span class="n">sampleNum</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">lambd</span> <span class="o">*</span> <span class="n">sampleNum</span><span class="p">))</span><span class="o">*</span><span class="n">label</span><span class="o">*</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span class="line">        <span class="n">new_weight</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">    <span class="c"># projection</span>
</span><span class="line">    <span class="n">norm2</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class="line">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">32</span><span class="o">*</span><span class="mi">32</span><span class="p">):</span>
</span><span class="line">        <span class="n">norm2</span> <span class="o">+=</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">new_weight</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span>
</span><span class="line">    <span class="n">norm2</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">norm2</span><span class="p">)</span>
</span><span class="line">    <span class="k">if</span> <span class="n">norm2</span> <span class="o">&gt;</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">lambd</span><span class="p">)):</span>
</span><span class="line">        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">32</span><span class="o">*</span><span class="mi">32</span><span class="p">):</span>
</span><span class="line">            <span class="n">G_WEIGHT</span><span class="p">[</span><span class="n">modelNum</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_weight</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">/</span><span class="p">(</span><span class="n">norm2</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">lambd</span><span class="p">))</span>
</span><span class="line">    <span class="k">else</span><span class="p">:</span>
</span><span class="line">        <span class="n">G_WEIGHT</span><span class="p">[</span><span class="n">modelNum</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_weight</span>
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">train_one_sample</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">sampleNum</span><span class="p">):</span>
</span><span class="line">    <span class="k">for</span> <span class="n">modelNum</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
</span><span class="line">        <span class="n">label</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
</span><span class="line">        <span class="k">if</span> <span class="n">num</span> <span class="o">==</span> <span class="n">modelNum</span><span class="p">:</span>
</span><span class="line">            <span class="n">label</span> <span class="o">=</span> <span class="mi">1</span>
</span><span class="line">        <span class="n">train_one_model</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">sampleNum</span><span class="p">,</span> <span class="n">modelNum</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="k">if</span> <span class="n">__name__</span><span class="o">==</span> <span class="s">&quot;__main__&quot;</span><span class="p">:</span>
</span><span class="line">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
</span><span class="line">        <span class="n">G_WEIGHT</span><span class="o">.</span><span class="n">append</span><span class="p">([])</span>
</span><span class="line">        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">32</span> <span class="o">*</span> <span class="mi">32</span><span class="p">):</span>
</span><span class="line">            <span class="n">G_WEIGHT</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">    <span class="n">dirpath</span> <span class="o">=</span> <span class="s">&quot;./trainingDigits/&quot;</span>
</span><span class="line">    <span class="n">files</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">dirpath</span><span class="p">)</span>
</span><span class="line">    <span class="n">sampleNum</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class="line">    <span class="k">for</span> <span class="nb">file</span> <span class="ow">in</span> <span class="n">files</span><span class="p">:</span>
</span><span class="line">        <span class="k">print</span> <span class="s">&quot;training:&quot;</span><span class="p">,</span> <span class="nb">file</span>
</span><span class="line">        <span class="n">data</span> <span class="o">=</span> <span class="n">parse_image</span><span class="p">(</span><span class="n">dirpath</span> <span class="o">+</span> <span class="nb">file</span><span class="p">)</span>
</span><span class="line">        <span class="n">num</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">file</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span><span class="line">        <span class="n">sampleNum</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class="line">        <span class="n">train_one_sample</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">sampleNum</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">    <span class="c"># test</span>
</span><span class="line">    <span class="n">testdir</span> <span class="o">=</span> <span class="s">&quot;./testDigits/&quot;</span>
</span><span class="line">    <span class="n">files</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">testdir</span><span class="p">)</span>
</span><span class="line">    <span class="n">right</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class="line">    <span class="n">wrong</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class="line">    <span class="n">can_not_classify</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class="line">    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class="line">    <span class="k">for</span> <span class="nb">file</span> <span class="ow">in</span> <span class="n">files</span><span class="p">:</span>
</span><span class="line">        <span class="n">total</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class="line">        <span class="n">data</span> <span class="o">=</span> <span class="n">parse_image</span><span class="p">(</span><span class="n">testdir</span> <span class="o">+</span> <span class="nb">file</span><span class="p">)</span>
</span><span class="line">        <span class="k">print</span> <span class="s">&quot;testing:&quot;</span><span class="p">,</span> <span class="nb">file</span>
</span><span class="line">        <span class="n">num</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">file</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span><span class="line">        <span class="n">classify_failed</span> <span class="o">=</span> <span class="bp">True</span>
</span><span class="line">        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
</span><span class="line">            <span class="n">pvalue</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">G_WEIGHT</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">data</span><span class="p">)</span>
</span><span class="line">            <span class="k">if</span> <span class="n">pvalue</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span class="line">                <span class="n">classify_failed</span> <span class="o">=</span> <span class="bp">False</span>
</span><span class="line">                <span class="k">print</span> <span class="n">i</span><span class="p">,</span> <span class="s">&quot;prdict:&quot;</span><span class="p">,</span> <span class="mi">1</span>
</span><span class="line">                <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">num</span><span class="p">:</span>
</span><span class="line">                    <span class="n">right</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class="line">                <span class="k">else</span><span class="p">:</span>
</span><span class="line">                    <span class="n">wrong</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class="line">            <span class="k">else</span><span class="p">:</span>
</span><span class="line">                <span class="k">print</span> <span class="n">i</span><span class="p">,</span> <span class="s">&quot;prdict:&quot;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span>
</span><span class="line">        <span class="k">if</span> <span class="n">classify_failed</span><span class="p">:</span>
</span><span class="line">            <span class="n">can_not_classify</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class="line">
</span><span class="line">    <span class="k">print</span> <span class="s">&quot;right=&quot;</span><span class="p">,</span> <span class="n">right</span>
</span><span class="line">    <span class="k">print</span> <span class="s">&quot;wrong=&quot;</span><span class="p">,</span> <span class="n">wrong</span>
</span><span class="line">    <span class="k">print</span> <span class="s">&quot;can_not_classify=&quot;</span><span class="p">,</span> <span class="n">can_not_classify</span>
</span><span class="line">    <span class="k">print</span> <span class="s">&quot;total=&quot;</span><span class="p">,</span> <span class="n">total</span>
</span><span class="line">
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>训练出来的模型测试结果如下：</p>

<pre class="sh-bash"><code>right= 849
</code><code>wrong= 46
</code><code>can_not_classify= 72
</code><code>total= 946</code></pre>

<p>一共有946个测试样本，其中46个分类错误，72个没有找到分类，849个正确分类，正确分类率89.7%。$\lambda$取值为0.5。我也没有仔细调整$\lambda$的取值，不过看来结果还是慢不错的。但比起SMO算法实现的svm效果要差一些。但是pegasos的优势是快啊，同样的1934个训练样本，基于SMO的svm，花了3、4个小时训练，而pegasos算法只用了30多秒，逆天了。</p>

<p>实现例子的代码和数据可以<a href="https://github.com/liuhongjiang/blog_projects/tree/master/pegasos">在github上下载</a>。pegasos有两个版本，pegasos2.py是pegasos.py的升级版，用了numpy库，使得代码更精简好看，同时运行效率更高。这个目录下还包含了论文的pdf文档Pegasos.pdf。</p>

<p>PS：发现numpy和scipy、matplotlib真是好东西啊，python数学运算离不开。另外发现了一个讲numpy/scipy文档翻译为中文的网站<a href="http://pyscin.appspot.com/html/index.html">用Python做科学计算</a>，好东西啊。</p>

<p>还发现了一个和机器学习相关的网站<a href="http://hunch.net/">http://hunch.net/</a>，有很不多不错的学术方面的东西。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ADMM and Large Scale Regression]]></title>
    <link href="http://wxwidget.github.io/blog/2013/11/08/admm-and-large-scale-regression/"/>
    <updated>2013-11-08T00:00:00+08:00</updated>
    <id>http://wxwidget.github.io/blog/2013/11/08/admm-and-large-scale-regression</id>
    <content type="html"><![CDATA[<h2 id="section">预备知识</h2>

<p>共轭函数，凸优化，对偶函数，对偶问题</p>

<ol>
  <li>对偶问题</li>
</ol>

<p>首先，以等价约束的凸优化问题为例：</p>

<script type="math/tex; mode=display">
\text{minimize} \; f(x)  \\\\
\text{subject to} \; Ax = b 
</script>

<p>f(x)是凸函数, x是N维变量</p>

<p>该问题的拉格朗日问题是：</p>

<script type="math/tex; mode=display"> 
L(x,y) = f(x) + y^t(Ax-b)
</script>

<p>对偶函数：
$$
g(y) = \inf_{x}{L(x,y)} = -f^\star(-A^Ty)-b^Ty
$$</p>

<p>y是对偶变量，$f^\star$是f的<a href="http://en.wikipedia.org/wiki/Convex_conjugate">凸共轭函数</a></p>

<p>对偶问题</p>

<script type="math/tex; mode=display">
\text{maximize}\; g(y)
</script>

<p>ADMM的方法：先确定y，然后根据y得到x;交换顺序，确定x，计算y</p>

<script type="math/tex; mode=display">
x^{k+1} = argminL(x,y^k) \\
y^{k+1} = y^k + \alpha^k (Ax^{k+1} - b)
</script>

<h2 id="section-1">相关资料</h2>

<p>ADMM是一种通用的并行优化策略, 它可以非常方便的在分布式环境的迭代优化计算，ADMM的算法文档可参考:<a href="http://www.stanford.edu/~boyd/papers/pdf/admm_distr_stats.pdf">ADMM文档</a></p>

<ul>
  <li><a href="https://speakerdeck.com/pld/distributed-classification-with-admm">ADMM</a></li>
  <li><a href="http://www.stanford.edu/~boyd/papers/admm/mpi/">MPI example for alternating direction method of multipliers</a></li>
  <li><a href="http://www.stanford.edu/~boyd/papers/admm_distr_stats.html">Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers</a></li>
</ul>

<h2 id="section-2">算法</h2>
<ol>
  <li>paralled Dual-ADMM</li>
  <li>FISTA</li>
  <li>GRock</li>
</ol>

<h2 id="section-3">代码</h2>

<ul>
  <li><a href="https://github.com/intentmedia/admm">admm-hadoop</a></li>
  <li><a href="https://github.com/brianmartin/admm-lasso-without-mpi">admm-lasso-without-mpi</a></li>
  <li><a href="http://www.stanford.edu/~boyd/papers/admm/mpi/">admm-mpi</a></li>
  <li><a href="http://www.caam.rice.edu/~optimization/disparse/">Parallel and Distributed Sparse Optimization</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
